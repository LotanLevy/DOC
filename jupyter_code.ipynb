{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jupyter_code.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3+xsTqrGyQbSmZD0Ey7V6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LotanLevy/DOC/blob/master/jupyter_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUwpGRq-7bvr"
      },
      "source": [
        "### **Enviroment settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EpcrZ0KE25J"
      },
      "source": [
        "pip install tensorflow-gpu==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecouf20wMZcO",
        "outputId": "cca00b51-d39a-4b7c-b283-dd9b7ccaf59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL57WBVF74NY"
      },
      "source": [
        "### **Usefull Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygOL2asKHd8K"
      },
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications import mobilenet_v2, vgg16\n",
        "\n",
        "\"\"\"\n",
        "resize function for mnist data\n",
        "\"\"\"\n",
        "def resize(x, size=96):\n",
        "    x_out = []\n",
        "    for i in range(len(x)):\n",
        "      img = x[i]\n",
        "      if img.shape[-1] == 1:\n",
        "        img = cv2.cvtColor(x[i], cv2.COLOR_GRAY2RGB)\n",
        "      img = cv2.resize(img,dsize=(size,size))\n",
        "      x_out.append(img)\n",
        "    return np.array(x_out)\n",
        "\n",
        "\"\"\"\n",
        "Mobile net network faster then vgg but acheive worse results than vgg.\n",
        "Now only work for fmnist\n",
        "\"\"\"\n",
        "def mobilenet_v2_preprocessing(input_data):\n",
        "  return input_data.astype('float32')/ 255\n",
        "\n",
        "\"\"\"\n",
        "Should work for both mnist and imagenet test\n",
        "\"\"\"\n",
        "def vgg_preprocessing(input_data):\n",
        "  # return vgg16.preprocess_input(resize(np.copy(input_data).astype('float32'), size=size))\n",
        "    return vgg16.preprocess_input(np.copy(input_data.astype('float32')))\n",
        "\n",
        "def read_paths_file(path_to_paths_file):\n",
        "  with open(path_to_paths_file, 'r') as f:\n",
        "    return [line[:-1] for line in f]\n",
        "\n",
        "def read_labels_file(path_to_labels_file):\n",
        "  with open(path_to_labels_file, 'r') as f:\n",
        "    return [int(line[:-1]) for line in f]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIEoU55O9kbG"
      },
      "source": [
        "### **Dataloaders classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHo-SyQ4cVZC"
      },
      "source": [
        "import os\n",
        "import numpy as np \n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"\n",
        "Data loader for fmnist data (gets the full data and their labels in the constructor)\n",
        "\"\"\"\n",
        "class DataIter:\n",
        "  def __init__(self, data, labels, batch_size, classes_num, shuffle=False, preprocess_func=lambda x:x):\n",
        "    if labels is not None:\n",
        "        assert(len(data) == len(labels))\n",
        "        self.labels = np.array(labels)\n",
        "    else:\n",
        "      self.labels = None\n",
        "\n",
        "    self.preprocess_func = preprocess_func\n",
        "\n",
        "    self.data = data\n",
        "    self.classes_num = classes_num\n",
        "    self.batch_size = batch_size\n",
        "    self.indices = np.arange(len(self.data)).astype(np.int)\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indices)\n",
        "    self.cur_idx = 0\n",
        "\n",
        "  def next(self):\n",
        "    relevant_indices = self.indices[self.cur_idx: self.cur_idx + self.batch_size]\n",
        "    self.cur_idx += self.batch_size\n",
        "    images = self.data[relevant_indices]\n",
        "    if self.labels is not None:\n",
        "      labels = self.labels[relevant_indices]\n",
        "      labels = tf.keras.utils.to_categorical(labels, num_classes=self.classes_num)\n",
        "    else:\n",
        "      labels = None\n",
        "    return resize(self.preprocess_func(images), size), labels\n",
        "\n",
        "  def get_all_data(self, size=None):\n",
        "    if size is None:\n",
        "      size = len(self.data)\n",
        "    return resize(self.preprocess_func(self.data[:size]), size), None\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Data iterator that loads the data from a path only when a batch called (next and get_all_data)\n",
        "\"\"\"\n",
        "class DirIter:\n",
        "    def __init__(self, paths, labels, batch_size, input_size, classes_num, shuffle=False, preprocess_func=lambda x:x):\n",
        "      if labels is not None:\n",
        "        assert(len(paths) == len(labels))\n",
        "        self.labels = np.array(labels)\n",
        "      else:\n",
        "        self.labels = None\n",
        "      self.preprocess_func = preprocess_func\n",
        "\n",
        "      self.paths = paths\n",
        "      self.classes_num = classes_num\n",
        "      self.batch_size = batch_size\n",
        "      self.indices = np.arange(len(self.paths)).astype(np.int)\n",
        "      self.input_size = input_size\n",
        "      self.shuffle = shuffle\n",
        "      self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.paths)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      if self.shuffle and len(self.indices) > 0:\n",
        "        np.random.shuffle(self.indices)\n",
        "      self.cur_idx = 0\n",
        "\n",
        "    def load_img(self, image_path):\n",
        "        image = Image.open(image_path, 'r')\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "        image = image.resize(self.input_size, Image.NEAREST)\n",
        "        image = np.array(image).astype(np.float32)\n",
        "        return np.expand_dims(image, axis=0)\n",
        "\n",
        "    def next(self):\n",
        "        relevant_indices = self.indices[self.cur_idx: self.cur_idx + self.batch_size]\n",
        "        self.cur_idx += self.batch_size\n",
        "        images = []\n",
        "        images = np.concatenate([self.load_img(self.paths[i]) for i in relevant_indices])\n",
        "        if self.labels is not None:\n",
        "          labels = self.labels[relevant_indices]\n",
        "          labels = tf.keras.utils.to_categorical(labels, num_classes=self.classes_num)\n",
        "        else:\n",
        "          labels = None\n",
        "        return self.preprocess_func(images), labels\n",
        "\n",
        "    def get_all_data(self, size=None):\n",
        "      if size is None:\n",
        "        size = len(self.paths)\n",
        "      relevant_paths = [self.paths[i] for i in self.indices[:size]]\n",
        "      images = np.concatenate([self.load_img(path) for path in relevant_paths])\n",
        "      return self.preprocess_func(images), relevant_paths\n",
        "\n",
        "    def has_next(self):\n",
        "      return self.cur_idx + self.batch_size < len(self.indices)\n",
        "\n",
        "    def set_cls2label_map(self, map):\n",
        "        self.cls2label = map\n",
        "\n",
        "    def write_data(self, output_path, loader_name):\n",
        "      with open(os.path.join(output_path, loader_name + \"_paths.txt\"), 'w') as f:\n",
        "        for p in self.paths:\n",
        "          f.write(p + \"\\n\")\n",
        "      with open(os.path.join(output_path, loader_name + \"_labels.txt\"), 'w') as f:\n",
        "        for l in self.labels:\n",
        "          f.write(str(l) + \"\\n\")\n",
        "\n",
        "def construct_with_files(path_file, label_file, batch_size, input_size, classes_num, shuffle=False, preprocess_func=lambda x:x):\n",
        "  paths = read_paths_file(path_file)\n",
        "  if label_file is not None:\n",
        "    labels = read_labels_file(label_file)\n",
        "  else:\n",
        "    labels = None\n",
        "  return DirIter(paths, labels, batch_size, input_size, classes_num, shuffle, preprocess_func)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Data loader that loads data from a dir of sub dirs, each sub dir contains data of one class.\n",
        "Works similarly to directory iterator, but it loads the data from a path only when a batch called (next and get_all_data)\n",
        "\"\"\"\n",
        "def get_iterators_by_root_dir(root_dir, batch_size, input_size, split_val, classes_num, shuffle=False, preprocess_func=lambda x:x):\n",
        "    dirs = os.listdir(root_dir)\n",
        "    length = len(max(dirs, key=len))\n",
        "\n",
        "    for dir in dirs: # Handle the sort problem pads the clas num with '0'\n",
        "        if len(dir) < length:\n",
        "          zeros = \"0\" * (length - len(dir))\n",
        "          new_name = zeros + dir\n",
        "\n",
        "          os.rename(os.path.join(root_dir, dir), os.path.join(root_dir, new_name))\n",
        "          print(\"old {}, new {}\".format(dir, new_name))\n",
        "\n",
        "    paths = []\n",
        "    labels = []\n",
        "    cls2label = dict()\n",
        "    label_idx = 0\n",
        "    for sub_dir in sorted(os.listdir(root_dir)):\n",
        "\n",
        "        full_path = os.path.join(root_dir, sub_dir)\n",
        "        if not os.path.isdir(full_path):\n",
        "            continue\n",
        "        cls2label[sub_dir] = label_idx\n",
        "        for file in os.listdir(full_path):\n",
        "            paths.append(os.path.join(full_path, file))\n",
        "            labels.append(label_idx)\n",
        "        label_idx += 1\n",
        "\n",
        "    print(cls2label)\n",
        "\n",
        "\n",
        "    assert len(paths) == len(labels)\n",
        "    if len(cls2label) != classes_num:\n",
        "        print(\"classes in directory doesn't match classes_num\")\n",
        "\n",
        "    if split_val > 0:\n",
        "      X_train, X_test, y_train, y_test = train_test_split(paths, labels, test_size=split_val, shuffle=shuffle)\n",
        "    else:\n",
        "      X_train, X_test, y_train, y_test = paths, [], labels, []\n",
        "\n",
        "    train_iter = DirIter(X_train, y_train, batch_size, input_size, classes_num, shuffle=True, preprocess_func=preprocess_func)\n",
        "    val_iter = DirIter(X_test, y_test, batch_size, input_size, classes_num, shuffle=True, preprocess_func=preprocess_func)\n",
        "\n",
        "    train_iter.set_cls2label_map(cls2label)\n",
        "    val_iter.set_cls2label_map(cls2label)\n",
        "    return train_iter, val_iter\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkCrf-M--2H4"
      },
      "source": [
        "###**Dataset dataloaders constructors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTH9ooTDivN"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "\n",
        "def get_fmnist_data_loaders():\n",
        "  # dataset\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "  #Splitting the into subsets data\n",
        "  x_train_s, x_test_s, x_test_b = [], [], []\n",
        "  x_ref, y_ref = [], []\n",
        "\n",
        "  x_train_shape = x_train.shape\n",
        "  #train data\n",
        "  for i in range(len(x_train)):\n",
        "      if y_train[i] == 7: #Sneakers is 7\n",
        "          temp = x_train[i]\n",
        "          x_train_s.append(temp.reshape((x_train_shape[1:])))\n",
        "      else:\n",
        "          temp = x_train[i]\n",
        "          x_ref.append(temp.reshape((x_train_shape[1:])))\n",
        "          y_ref.append(y_train[i])\n",
        "\n",
        "  x_ref, y_ref = np.array(x_ref), np.array(y_ref)\n",
        "\n",
        "  #test data\n",
        "  for i in range(len(x_test)):\n",
        "      if y_test[i] == 7: #Sneakers is 7\n",
        "          temp = x_test[i,:,:,:]\n",
        "          x_test_s.append(temp.reshape((x_train_shape[1:])))\n",
        "\n",
        "      if y_test[i] == 9: #Boots is 9\n",
        "          temp = x_test[i,:,:,:]\n",
        "          x_test_b.append(temp.reshape((x_train_shape[1:])))\n",
        "\n",
        "  #tdata loaders\n",
        "  train_s_loader = DataIter(np.array(x_train_s), None, batchsize, classes, shuffle=True, preprocess_func=preprocessing_func)\n",
        "  ref_loader = DataIter(np.array(x_ref), np.array(y_ref), batchsize, classes, shuffle=True, preprocess_func=preprocessing_func)\n",
        "\n",
        "  test_s_loader = DataIter(np.array(x_test_s), None, batchsize, classes, preprocess_func=preprocessing_func)\n",
        "  test_b_loader = DataIter(np.array(x_test_b), None, batchsize, classes, preprocess_func=preprocessing_func)\n",
        "  return  train_s_loader, ref_loader, test_s_loader, test_b_loader\n",
        "\n",
        "\n",
        "def get_imagenet_clatech_loaders(ref_path, tar_path, alien_path, batchsize, input_size, split_val, cls_num, shuffle=False, preprocess_func=lambda x:x):\n",
        "  ref_loader, i1 = get_iterators_by_root_dir(ref_path, batchsize, input_size, 0, cls_num, shuffle=shuffle, preprocess_func=preprocess_func)\n",
        "  train_s_loader, test_s_loader = get_iterators_by_root_dir(tar_path, batchsize, input_size, split_val, cls_num, shuffle=shuffle, preprocess_func=preprocess_func)\n",
        "  test_alien_loader, i2 = get_iterators_by_root_dir(alien_path, batchsize, input_size, 0, cls_num, shuffle=shuffle, preprocess_func=preprocess_func)\n",
        "  print(len(ref_loader), len(i1))\n",
        "  print(len(train_s_loader), len(test_s_loader))\n",
        "  print(len(test_alien_loader), len(i2))\n",
        "\n",
        "  return  train_s_loader, ref_loader, test_s_loader, test_alien_loader"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZgGJobg_KvE"
      },
      "source": [
        "## **Run Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjiyMA8pu6gY",
        "outputId": "557ffc18-3463-4c0f-ca6d-18d8912be518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "\"\"\"\n",
        "Outputs directories\n",
        "\"\"\"\n",
        "# main output folder\n",
        "output_path = \"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "if not os.path.exists(output_path):\n",
        "  os.makedirs(output_path)\n",
        "#check points folder\n",
        "ckpt_path = os.path.join(output_path, \"ckpts\")\n",
        "if not os.path.exists(ckpt_path):\n",
        "  os.makedirs(ckpt_path)\n",
        "#Logs folder\n",
        "epochs_log_dir = os.path.join(os.path.join(output_path, \"epochs_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
        "batchs_log_dir = os.path.join(os.path.join(output_path, \"batchs_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
        "\n",
        "\n",
        "# MobileNetV2\n",
        "# size = 96\n",
        "# preprocessing_func = mobilenet_v2_preprocessing\n",
        "# first_trained_layer_name = \"block_13_expand\"\n",
        "# alpha = 0.5 #for MobileNetV2\n",
        "# network_constractor = lambda : tf.keras.applications.MobileNetV2(include_top=True, input_shape=(size, size, 3), alpha=alpha, weights='imagenet')\n",
        "\n",
        "\n",
        "# VGG16\n",
        "size = 224\n",
        "preprocessing_func = vgg_preprocessing\n",
        "first_trained_layer_name =  \"block5_conv1\"\n",
        "network_constractor = lambda : tf.keras.applications.VGG16(include_top=True, input_shape=(size, size, 3), weights='imagenet')\n",
        "test_size = 200\n",
        "\n",
        "\n",
        "\n",
        "lambda_ = 0.1 #for compact loss\n",
        "\n",
        "# fmnist data\n",
        "# classes = 10\n",
        "# batchsize = 2\n",
        "# train_s_loader, ref_loader, test_s_loader, test_b_loader = get_fmnist_data_loaders()\n",
        "\n",
        "# # imagenet clatech data\n",
        "REFERENCE_PATH = \"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\"\n",
        "TARGET_PATH = \"/content/drive/My Drive/Colab Notebooks/affordances/datasets/stab_data\"\n",
        "ALIEN_PATH = \"/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization\"\n",
        "classes = 1000\n",
        "batchsize = 2\n",
        "split_val = 0.2\n",
        "\n",
        "train_s_loader, ref_loader, test_s_loader, test_b_loader = get_imagenet_clatech_loaders(REFERENCE_PATH, TARGET_PATH, ALIEN_PATH, batchsize, (size,size), split_val, classes, shuffle=True, preprocess_func=preprocessing_func)\n",
        "\n",
        "path_file = (output_path, \"target_test\"+\"_paths.txt\")\n",
        "label_file = (output_path, \"target_test\"+\"_labels.txt\")\n",
        "\n",
        "\n",
        "train_s_loader.write_data(output_path, \"target_train\")\n",
        "test_s_loader.write_data(output_path, \"target_test\")\n",
        "test_b_loader.write_data(output_path, \"alien_test\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'0000000000000000': 0, '0000000000000001': 1, '0000000000000002': 2, '0000000000000003': 3, '0000000000000004': 4, '0000000000000005': 5, '0000000000000006': 6, '0000000000000007': 7, '0000000000000008': 8, '0000000000000009': 9, '0000000000000010': 10, '0000000000000011': 11, '0000000000000012': 12, '0000000000000013': 13, '0000000000000014': 14, '0000000000000015': 15, '0000000000000016': 16, '0000000000000017': 17, '0000000000000018': 18, '0000000000000019': 19, '0000000000000020': 20, '0000000000000021': 21, '0000000000000022': 22, '0000000000000023': 23, '0000000000000024': 24, '0000000000000025': 25, '0000000000000026': 26, '0000000000000027': 27, '0000000000000028': 28, '0000000000000029': 29, '0000000000000030': 30, '0000000000000031': 31, '0000000000000032': 32, '0000000000000033': 33, '0000000000000034': 34, '0000000000000035': 35, '0000000000000036': 36, '0000000000000037': 37, '0000000000000038': 38, '0000000000000039': 39, '0000000000000040': 40, '0000000000000041': 41, '0000000000000042': 42, '0000000000000043': 43, '0000000000000044': 44, '0000000000000045': 45, '0000000000000046': 46, '0000000000000047': 47, '0000000000000048': 48, '0000000000000049': 49, '0000000000000050': 50, '0000000000000051': 51, '0000000000000052': 52, '0000000000000053': 53, '0000000000000054': 54, '0000000000000055': 55, '0000000000000056': 56, '0000000000000057': 57, '0000000000000058': 58, '0000000000000059': 59, '0000000000000060': 60, '0000000000000061': 61, '0000000000000062': 62, '0000000000000063': 63, '0000000000000064': 64, '0000000000000065': 65, '0000000000000066': 66, '0000000000000067': 67, '0000000000000068': 68, '0000000000000069': 69, '0000000000000070': 70, '0000000000000071': 71, '0000000000000072': 72, '0000000000000073': 73, '0000000000000074': 74, '0000000000000075': 75, '0000000000000076': 76, '0000000000000077': 77, '0000000000000078': 78, '0000000000000079': 79, '0000000000000080': 80, '0000000000000081': 81, '0000000000000082': 82, '0000000000000083': 83, '0000000000000084': 84, '0000000000000085': 85, '0000000000000086': 86, '0000000000000087': 87, '0000000000000088': 88, '0000000000000089': 89, '0000000000000090': 90, '0000000000000091': 91, '0000000000000092': 92, '0000000000000093': 93, '0000000000000094': 94, '0000000000000095': 95, '0000000000000096': 96, '0000000000000097': 97, '0000000000000098': 98, '0000000000000099': 99, '0000000000000100': 100, '0000000000000101': 101, '0000000000000102': 102, '0000000000000103': 103, '0000000000000104': 104, '0000000000000105': 105, '0000000000000106': 106, '0000000000000107': 107, '0000000000000108': 108, '0000000000000109': 109, '0000000000000110': 110, '0000000000000111': 111, '0000000000000112': 112, '0000000000000113': 113, '0000000000000114': 114, '0000000000000115': 115, '0000000000000116': 116, '0000000000000117': 117, '0000000000000118': 118, '0000000000000119': 119, '0000000000000120': 120, '0000000000000121': 121, '0000000000000122': 122, '0000000000000123': 123, '0000000000000124': 124, '0000000000000125': 125, '0000000000000126': 126, '0000000000000127': 127, '0000000000000128': 128, '0000000000000129': 129, '0000000000000130': 130, '0000000000000131': 131, '0000000000000132': 132, '0000000000000133': 133, '0000000000000134': 134, '0000000000000135': 135, '0000000000000136': 136, '0000000000000137': 137, '0000000000000138': 138, '0000000000000139': 139, '0000000000000140': 140, '0000000000000141': 141, '0000000000000142': 142, '0000000000000143': 143, '0000000000000144': 144, '0000000000000145': 145, '0000000000000146': 146, '0000000000000147': 147, '0000000000000148': 148, '0000000000000149': 149, '0000000000000150': 150, '0000000000000151': 151, '0000000000000152': 152, '0000000000000153': 153, '0000000000000154': 154, '0000000000000155': 155, '0000000000000156': 156, '0000000000000157': 157, '0000000000000158': 158, '0000000000000159': 159, '0000000000000160': 160, '0000000000000161': 161, '0000000000000162': 162, '0000000000000163': 163, '0000000000000164': 164, '0000000000000165': 165, '0000000000000166': 166, '0000000000000167': 167, '0000000000000168': 168, '0000000000000169': 169, '0000000000000170': 170, '0000000000000171': 171, '0000000000000172': 172, '0000000000000173': 173, '0000000000000174': 174, '0000000000000175': 175, '0000000000000176': 176, '0000000000000177': 177, '0000000000000178': 178, '0000000000000179': 179, '0000000000000180': 180, '0000000000000181': 181, '0000000000000182': 182, '0000000000000183': 183, '0000000000000184': 184, '0000000000000185': 185, '0000000000000186': 186, '0000000000000187': 187, '0000000000000188': 188, '0000000000000189': 189, '0000000000000190': 190, '0000000000000191': 191, '0000000000000192': 192, '0000000000000193': 193, '0000000000000194': 194, '0000000000000195': 195, '0000000000000196': 196, '0000000000000197': 197, '0000000000000198': 198, '0000000000000199': 199, '0000000000000200': 200, '0000000000000201': 201, '0000000000000202': 202, '0000000000000203': 203, '0000000000000204': 204, '0000000000000205': 205, '0000000000000206': 206, '0000000000000207': 207, '0000000000000208': 208, '0000000000000209': 209, '0000000000000210': 210, '0000000000000211': 211, '0000000000000212': 212, '0000000000000213': 213, '0000000000000214': 214, '0000000000000215': 215, '0000000000000216': 216, '0000000000000217': 217, '0000000000000218': 218, '0000000000000219': 219, '0000000000000220': 220, '0000000000000221': 221, '0000000000000222': 222, '0000000000000223': 223, '0000000000000224': 224, '0000000000000225': 225, '0000000000000226': 226, '0000000000000227': 227, '0000000000000228': 228, '0000000000000229': 229, '0000000000000230': 230, '0000000000000231': 231, '0000000000000232': 232, '0000000000000233': 233, '0000000000000234': 234, '0000000000000235': 235, '0000000000000236': 236, '0000000000000237': 237, '0000000000000238': 238, '0000000000000239': 239, '0000000000000240': 240, '0000000000000241': 241, '0000000000000242': 242, '0000000000000243': 243, '0000000000000244': 244, '0000000000000245': 245, '0000000000000246': 246, '0000000000000247': 247, '0000000000000248': 248, '0000000000000249': 249, '0000000000000250': 250, '0000000000000251': 251, '0000000000000252': 252, '0000000000000253': 253, '0000000000000254': 254, '0000000000000255': 255, '0000000000000256': 256, '0000000000000257': 257, '0000000000000258': 258, '0000000000000259': 259, '0000000000000260': 260, '0000000000000261': 261, '0000000000000262': 262, '0000000000000263': 263, '0000000000000264': 264, '0000000000000265': 265, '0000000000000266': 266, '0000000000000267': 267, '0000000000000268': 268, '0000000000000269': 269, '0000000000000270': 270, '0000000000000271': 271, '0000000000000272': 272, '0000000000000273': 273, '0000000000000274': 274, '0000000000000275': 275, '0000000000000276': 276, '0000000000000277': 277, '0000000000000278': 278, '0000000000000279': 279, '0000000000000280': 280, '0000000000000281': 281, '0000000000000282': 282, '0000000000000283': 283, '0000000000000284': 284, '0000000000000285': 285, '0000000000000286': 286, '0000000000000287': 287, '0000000000000288': 288, '0000000000000289': 289, '0000000000000290': 290, '0000000000000291': 291, '0000000000000292': 292, '0000000000000293': 293, '0000000000000294': 294, '0000000000000295': 295, '0000000000000296': 296, '0000000000000297': 297, '0000000000000298': 298, '0000000000000299': 299, '0000000000000300': 300, '0000000000000301': 301, '0000000000000302': 302, '0000000000000303': 303, '0000000000000304': 304, '0000000000000305': 305, '0000000000000306': 306, '0000000000000307': 307, '0000000000000308': 308, '0000000000000309': 309, '0000000000000310': 310, '0000000000000311': 311, '0000000000000312': 312, '0000000000000313': 313, '0000000000000314': 314, '0000000000000315': 315, '0000000000000316': 316, '0000000000000317': 317, '0000000000000318': 318, '0000000000000319': 319, '0000000000000320': 320, '0000000000000321': 321, '0000000000000322': 322, '0000000000000323': 323, '0000000000000324': 324, '0000000000000325': 325, '0000000000000326': 326, '0000000000000327': 327, '0000000000000328': 328, '0000000000000329': 329, '0000000000000330': 330, '0000000000000331': 331, '0000000000000332': 332, '0000000000000333': 333, '0000000000000334': 334, '0000000000000335': 335, '0000000000000336': 336, '0000000000000337': 337, '0000000000000338': 338, '0000000000000339': 339, '0000000000000340': 340, '0000000000000341': 341, '0000000000000342': 342, '0000000000000343': 343, '0000000000000344': 344, '0000000000000345': 345, '0000000000000346': 346, '0000000000000347': 347, '0000000000000348': 348, '0000000000000349': 349, '0000000000000350': 350, '0000000000000351': 351, '0000000000000352': 352, '0000000000000353': 353, '0000000000000354': 354, '0000000000000355': 355, '0000000000000356': 356, '0000000000000357': 357, '0000000000000358': 358, '0000000000000359': 359, '0000000000000360': 360, '0000000000000361': 361, '0000000000000362': 362, '0000000000000363': 363, '0000000000000364': 364, '0000000000000365': 365, '0000000000000366': 366, '0000000000000367': 367, '0000000000000368': 368, '0000000000000369': 369, '0000000000000370': 370, '0000000000000371': 371, '0000000000000372': 372, '0000000000000373': 373, '0000000000000374': 374, '0000000000000375': 375, '0000000000000376': 376, '0000000000000377': 377, '0000000000000378': 378, '0000000000000379': 379, '0000000000000380': 380, '0000000000000381': 381, '0000000000000382': 382, '0000000000000383': 383, '0000000000000384': 384, '0000000000000385': 385, '0000000000000386': 386, '0000000000000387': 387, '0000000000000388': 388, '0000000000000389': 389, '0000000000000390': 390, '0000000000000391': 391, '0000000000000392': 392, '0000000000000393': 393, '0000000000000394': 394, '0000000000000395': 395, '0000000000000396': 396, '0000000000000397': 397, '0000000000000398': 398, '0000000000000399': 399, '0000000000000400': 400, '0000000000000401': 401, '0000000000000402': 402, '0000000000000403': 403, '0000000000000404': 404, '0000000000000405': 405, '0000000000000406': 406, '0000000000000407': 407, '0000000000000408': 408, '0000000000000409': 409, '0000000000000410': 410, '0000000000000411': 411, '0000000000000412': 412, '0000000000000413': 413, '0000000000000414': 414, '0000000000000415': 415, '0000000000000416': 416, '0000000000000417': 417, '0000000000000418': 418, '0000000000000419': 419, '0000000000000420': 420, '0000000000000421': 421, '0000000000000422': 422, '0000000000000423': 423, '0000000000000424': 424, '0000000000000425': 425, '0000000000000426': 426, '0000000000000427': 427, '0000000000000428': 428, '0000000000000429': 429, '0000000000000430': 430, '0000000000000431': 431, '0000000000000432': 432, '0000000000000433': 433, '0000000000000434': 434, '0000000000000435': 435, '0000000000000436': 436, '0000000000000437': 437, '0000000000000438': 438, '0000000000000439': 439, '0000000000000440': 440, '0000000000000441': 441, '0000000000000442': 442, '0000000000000443': 443, '0000000000000444': 444, '0000000000000445': 445, '0000000000000446': 446, '0000000000000447': 447, '0000000000000448': 448, '0000000000000449': 449, '0000000000000450': 450, '0000000000000451': 451, '0000000000000452': 452, '0000000000000453': 453, '0000000000000454': 454, '0000000000000455': 455, '0000000000000456': 456, '0000000000000457': 457, '0000000000000458': 458, '0000000000000459': 459, '0000000000000460': 460, '0000000000000461': 461, '0000000000000462': 462, '0000000000000463': 463, '0000000000000464': 464, '0000000000000465': 465, '0000000000000466': 466, '0000000000000467': 467, '0000000000000468': 468, '0000000000000469': 469, '0000000000000470': 470, '0000000000000471': 471, '0000000000000472': 472, '0000000000000473': 473, '0000000000000474': 474, '0000000000000475': 475, '0000000000000476': 476, '0000000000000477': 477, '0000000000000478': 478, '0000000000000479': 479, '0000000000000480': 480, '0000000000000481': 481, '0000000000000482': 482, '0000000000000483': 483, '0000000000000484': 484, '0000000000000485': 485, '0000000000000486': 486, '0000000000000487': 487, '0000000000000488': 488, '0000000000000489': 489, '0000000000000490': 490, '0000000000000491': 491, '0000000000000492': 492, '0000000000000493': 493, '0000000000000494': 494, '0000000000000495': 495, '0000000000000496': 496, '0000000000000497': 497, '0000000000000498': 498, '0000000000000499': 499, '0000000000000500': 500, '0000000000000501': 501, '0000000000000502': 502, '0000000000000503': 503, '0000000000000504': 504, '0000000000000505': 505, '0000000000000506': 506, '0000000000000507': 507, '0000000000000508': 508, '0000000000000509': 509, '0000000000000510': 510, '0000000000000511': 511, '0000000000000512': 512, '0000000000000513': 513, '0000000000000514': 514, '0000000000000515': 515, '0000000000000516': 516, '0000000000000517': 517, '0000000000000518': 518, '0000000000000519': 519, '0000000000000520': 520, '0000000000000521': 521, '0000000000000522': 522, '0000000000000523': 523, '0000000000000524': 524, '0000000000000525': 525, '0000000000000526': 526, '0000000000000527': 527, '0000000000000528': 528, '0000000000000529': 529, '0000000000000530': 530, '0000000000000531': 531, '0000000000000532': 532, '0000000000000533': 533, '0000000000000534': 534, '0000000000000535': 535, '0000000000000536': 536, '0000000000000537': 537, '0000000000000538': 538, '0000000000000539': 539, '0000000000000540': 540, '0000000000000541': 541, '0000000000000542': 542, '0000000000000543': 543, '0000000000000544': 544, '0000000000000545': 545, '0000000000000546': 546, '0000000000000547': 547, '0000000000000548': 548, '0000000000000549': 549, '0000000000000550': 550, '0000000000000551': 551, '0000000000000552': 552, '0000000000000553': 553, '0000000000000554': 554, '0000000000000555': 555, '0000000000000556': 556, '0000000000000557': 557, '0000000000000558': 558, '0000000000000559': 559, '0000000000000560': 560, '0000000000000561': 561, '0000000000000562': 562, '0000000000000563': 563, '0000000000000564': 564, '0000000000000565': 565, '0000000000000566': 566, '0000000000000567': 567, '0000000000000568': 568, '0000000000000569': 569, '0000000000000570': 570, '0000000000000571': 571, '0000000000000572': 572, '0000000000000573': 573, '0000000000000574': 574, '0000000000000575': 575, '0000000000000576': 576, '0000000000000577': 577, '0000000000000578': 578, '0000000000000579': 579, '0000000000000580': 580, '0000000000000581': 581, '0000000000000582': 582, '0000000000000583': 583, '0000000000000584': 584, '0000000000000585': 585, '0000000000000586': 586, '0000000000000587': 587, '0000000000000588': 588, '0000000000000589': 589, '0000000000000590': 590, '0000000000000591': 591, '0000000000000592': 592, '0000000000000593': 593, '0000000000000594': 594, '0000000000000595': 595, '0000000000000596': 596, '0000000000000597': 597, '0000000000000598': 598, '0000000000000599': 599, '0000000000000600': 600, '0000000000000601': 601, '0000000000000602': 602, '0000000000000603': 603, '0000000000000604': 604, '0000000000000605': 605, '0000000000000606': 606, '0000000000000607': 607, '0000000000000608': 608, '0000000000000609': 609, '0000000000000610': 610, '0000000000000611': 611, '0000000000000612': 612, '0000000000000613': 613, '0000000000000614': 614, '0000000000000615': 615, '0000000000000616': 616, '0000000000000617': 617, '0000000000000618': 618, '0000000000000619': 619, '0000000000000620': 620, '0000000000000621': 621, '0000000000000622': 622, '0000000000000623': 623, '0000000000000624': 624, '0000000000000625': 625, '0000000000000626': 626, '0000000000000627': 627, '0000000000000628': 628, '0000000000000629': 629, '0000000000000630': 630, '0000000000000631': 631, '0000000000000632': 632, '0000000000000633': 633, '0000000000000634': 634, '0000000000000635': 635, '0000000000000636': 636, '0000000000000637': 637, '0000000000000638': 638, '0000000000000639': 639, '0000000000000640': 640, '0000000000000641': 641, '0000000000000642': 642, '0000000000000643': 643, '0000000000000644': 644, '0000000000000645': 645, '0000000000000646': 646, '0000000000000647': 647, '0000000000000648': 648, '0000000000000649': 649, '0000000000000650': 650, '0000000000000651': 651, '0000000000000652': 652, '0000000000000653': 653, '0000000000000654': 654, '0000000000000655': 655, '0000000000000656': 656, '0000000000000657': 657, '0000000000000658': 658, '0000000000000659': 659, '0000000000000660': 660, '0000000000000661': 661, '0000000000000662': 662, '0000000000000663': 663, '0000000000000664': 664, '0000000000000665': 665, '0000000000000666': 666, '0000000000000667': 667, '0000000000000668': 668, '0000000000000669': 669, '0000000000000670': 670, '0000000000000671': 671, '0000000000000672': 672, '0000000000000673': 673, '0000000000000674': 674, '0000000000000675': 675, '0000000000000676': 676, '0000000000000677': 677, '0000000000000678': 678, '0000000000000679': 679, '0000000000000680': 680, '0000000000000681': 681, '0000000000000682': 682, '0000000000000683': 683, '0000000000000684': 684, '0000000000000685': 685, '0000000000000686': 686, '0000000000000687': 687, '0000000000000688': 688, '0000000000000689': 689, '0000000000000690': 690, '0000000000000691': 691, '0000000000000692': 692, '0000000000000693': 693, '0000000000000694': 694, '0000000000000695': 695, '0000000000000696': 696, '0000000000000697': 697, '0000000000000698': 698, '0000000000000699': 699, '0000000000000700': 700, '0000000000000701': 701, '0000000000000702': 702, '0000000000000703': 703, '0000000000000704': 704, '0000000000000705': 705, '0000000000000706': 706, '0000000000000707': 707, '0000000000000708': 708, '0000000000000709': 709, '0000000000000710': 710, '0000000000000711': 711, '0000000000000712': 712, '0000000000000713': 713, '0000000000000714': 714, '0000000000000715': 715, '0000000000000716': 716, '0000000000000717': 717, '0000000000000718': 718, '0000000000000719': 719, '0000000000000720': 720, '0000000000000721': 721, '0000000000000722': 722, '0000000000000723': 723, '0000000000000724': 724, '0000000000000725': 725, '0000000000000726': 726, '0000000000000727': 727, '0000000000000728': 728, '0000000000000729': 729, '0000000000000730': 730, '0000000000000731': 731, '0000000000000732': 732, '0000000000000733': 733, '0000000000000734': 734, '0000000000000735': 735, '0000000000000736': 736, '0000000000000737': 737, '0000000000000738': 738, '0000000000000739': 739, '0000000000000740': 740, '0000000000000741': 741, '0000000000000742': 742, '0000000000000743': 743, '0000000000000744': 744, '0000000000000745': 745, '0000000000000746': 746, '0000000000000747': 747, '0000000000000748': 748, '0000000000000749': 749, '0000000000000750': 750, '0000000000000751': 751, '0000000000000752': 752, '0000000000000753': 753, '0000000000000754': 754, '0000000000000755': 755, '0000000000000756': 756, '0000000000000757': 757, '0000000000000758': 758, '0000000000000759': 759, '0000000000000760': 760, '0000000000000761': 761, '0000000000000762': 762, '0000000000000763': 763, '0000000000000764': 764, '0000000000000765': 765, '0000000000000766': 766, '0000000000000767': 767, '0000000000000768': 768, '0000000000000769': 769, '0000000000000770': 770, '0000000000000771': 771, '0000000000000772': 772, '0000000000000773': 773, '0000000000000774': 774, '0000000000000775': 775, '0000000000000776': 776, '0000000000000777': 777, '0000000000000778': 778, '0000000000000779': 779, '0000000000000780': 780, '0000000000000781': 781, '0000000000000782': 782, '0000000000000783': 783, '0000000000000784': 784, '0000000000000785': 785, '0000000000000786': 786, '0000000000000787': 787, '0000000000000788': 788, '0000000000000789': 789, '0000000000000790': 790, '0000000000000791': 791, '0000000000000792': 792, '0000000000000793': 793, '0000000000000794': 794, '0000000000000795': 795, '0000000000000796': 796, '0000000000000797': 797, '0000000000000798': 798, '0000000000000799': 799, '0000000000000800': 800, '0000000000000801': 801, '0000000000000802': 802, '0000000000000803': 803, '0000000000000804': 804, '0000000000000805': 805, '0000000000000806': 806, '0000000000000807': 807, '0000000000000808': 808, '0000000000000809': 809, '0000000000000810': 810, '0000000000000811': 811, '0000000000000812': 812, '0000000000000813': 813, '0000000000000814': 814, '0000000000000815': 815, '0000000000000816': 816, '0000000000000817': 817, '0000000000000818': 818, '0000000000000819': 819, '0000000000000820': 820, '0000000000000821': 821, '0000000000000822': 822, '0000000000000823': 823, '0000000000000824': 824, '0000000000000825': 825, '0000000000000826': 826, '0000000000000827': 827, '0000000000000828': 828, '0000000000000829': 829, '0000000000000830': 830, '0000000000000831': 831, '0000000000000832': 832, '0000000000000833': 833, '0000000000000834': 834, '0000000000000835': 835, '0000000000000836': 836, '0000000000000837': 837, '0000000000000838': 838, '0000000000000839': 839, '0000000000000840': 840, '0000000000000841': 841, '0000000000000842': 842, '0000000000000843': 843, '0000000000000844': 844, '0000000000000845': 845, '0000000000000846': 846, '0000000000000847': 847, '0000000000000848': 848, '0000000000000849': 849, '0000000000000850': 850, '0000000000000851': 851, '0000000000000852': 852, '0000000000000853': 853, '0000000000000854': 854, '0000000000000855': 855, '0000000000000856': 856, '0000000000000857': 857, '0000000000000858': 858, '0000000000000859': 859, '0000000000000860': 860, '0000000000000861': 861, '0000000000000862': 862, '0000000000000863': 863, '0000000000000864': 864, '0000000000000865': 865, '0000000000000866': 866, '0000000000000867': 867, '0000000000000868': 868, '0000000000000869': 869, '0000000000000870': 870, '0000000000000871': 871, '0000000000000872': 872, '0000000000000873': 873, '0000000000000874': 874, '0000000000000875': 875, '0000000000000876': 876, '0000000000000877': 877, '0000000000000878': 878, '0000000000000879': 879, '0000000000000880': 880, '0000000000000881': 881, '0000000000000882': 882, '0000000000000883': 883, '0000000000000884': 884, '0000000000000885': 885, '0000000000000886': 886, '0000000000000887': 887, '0000000000000888': 888, '0000000000000889': 889, '0000000000000890': 890, '0000000000000891': 891, '0000000000000892': 892, '0000000000000893': 893, '0000000000000894': 894, '0000000000000895': 895, '0000000000000896': 896, '0000000000000897': 897, '0000000000000898': 898, '0000000000000899': 899, '0000000000000900': 900, '0000000000000901': 901, '0000000000000902': 902, '0000000000000903': 903, '0000000000000904': 904, '0000000000000905': 905, '0000000000000906': 906, '0000000000000907': 907, '0000000000000908': 908, '0000000000000909': 909, '0000000000000910': 910, '0000000000000911': 911, '0000000000000912': 912, '0000000000000913': 913, '0000000000000914': 914, '0000000000000915': 915, '0000000000000916': 916, '0000000000000917': 917, '0000000000000918': 918, '0000000000000919': 919, '0000000000000920': 920, '0000000000000921': 921, '0000000000000922': 922, '0000000000000923': 923, '0000000000000924': 924, '0000000000000925': 925, '0000000000000926': 926, '0000000000000927': 927, '0000000000000928': 928, '0000000000000929': 929, '0000000000000930': 930, '0000000000000931': 931, '0000000000000932': 932, '0000000000000933': 933, '0000000000000934': 934, '0000000000000935': 935, '0000000000000936': 936, '0000000000000937': 937, '0000000000000938': 938, '0000000000000939': 939, '0000000000000940': 940, '0000000000000941': 941, '0000000000000942': 942, '0000000000000943': 943, '0000000000000944': 944, '0000000000000945': 945, '0000000000000946': 946, '0000000000000947': 947, '0000000000000948': 948, '0000000000000949': 949, '0000000000000950': 950, '0000000000000951': 951, '0000000000000952': 952, '0000000000000953': 953, '0000000000000954': 954, '0000000000000955': 955, '0000000000000956': 956, '0000000000000957': 957, '0000000000000958': 958, '0000000000000959': 959, '0000000000000960': 960, '0000000000000961': 961, '0000000000000962': 962, '0000000000000963': 963, '0000000000000964': 964, '0000000000000965': 965, '0000000000000966': 966, '0000000000000967': 967, '0000000000000968': 968, '0000000000000969': 969, '0000000000000970': 970, '0000000000000971': 971, '0000000000000972': 972, '0000000000000973': 973, '0000000000000974': 974, '0000000000000975': 975, '0000000000000976': 976, '0000000000000977': 977, '0000000000000978': 978, '0000000000000979': 979, '0000000000000980': 980, '0000000000000981': 981, '0000000000000982': 982, '0000000000000983': 983, '0000000000000984': 984, '0000000000000985': 985, '0000000000000986': 986, '0000000000000987': 987, '0000000000000988': 988, '0000000000000989': 989, '0000000000000990': 990, '0000000000000991': 991, '0000000000000992': 992, '0000000000000993': 993, '0000000000000994': 994, '0000000000000995': 995, '0000000000000996': 996, '0000000000000997': 997, '0000000000000998': 998, '0000000000000999': 999}\n",
            "{'0knife': 0, '0spear': 1, '0sword': 2, 'dagger': 3}\n",
            "classes in directory doesn't match classes_num\n",
            "old true, new 0true\n",
            "{'0true': 0, 'false': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3386 847\n",
            "71 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBvuSHZ6_wdO"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxB4w5RUD0kw",
        "outputId": "f276b8f0-fd07-483a-f4f8-f13e4f29d206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Loss function\n",
        "def compactness_loss(y_true, y_pred):\n",
        "    n_dim = np.shape(y_pred)[0]  # number of features vecs\n",
        "    k_dim = np.shape(y_pred)[1]  # feature vec dim\n",
        "    lc = 1/(k_dim*n_dim)* n_dim**2 * K.sum((y_pred - K.mean(y_pred,axis=0))**2,axis=[1]) / ((n_dim-1)**2)\n",
        "    return lc\n",
        "\n",
        "#Learning\n",
        "def train(target_dataloader, reference_dataloader, epoch_num):\n",
        "    print(\"Model build...\")\n",
        "\n",
        "    network = network_constractor()\n",
        "    #Freeze weight\n",
        "    for layer in network.layers:\n",
        "        if layer.name == first_trained_layer_name:\n",
        "            break\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "    # Secondary network\n",
        "    model_t = Model(inputs=network.input,outputs=network.layers[-2].output)\n",
        "    # Reference network\n",
        "    #Apply a Fully Connected Layer to R\n",
        "    # prediction = Dense(classes, activation='softmax')(model_t.output) # for fmnist\n",
        "    model_r = Model(inputs=model_t.input,outputs=network.layers[-1].output) # for imagenet\n",
        "    \n",
        "    #Compile\n",
        "    train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "    optimizer = SGD(lr=5e-5, decay=0.00005)\n",
        "    model_r.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[train_accuracy])\n",
        "    model_t.compile(optimizer=optimizer, loss=compactness_loss)\n",
        "\n",
        "    # Prints run settings\n",
        "    model_t.summary()\n",
        "    model_r.summary()\n",
        "    print(\"x_target is\", len(target_dataloader),'samples')\n",
        "    print(\"x_ref is\",len(reference_dataloader),'samples')\n",
        "\n",
        "    # run loggers\n",
        "    epochs_writer = tf.summary.create_file_writer(logdir=epochs_log_dir)\n",
        "    # batchs_writer = tf.summary.create_file_writer(logdir=batchs_log_dir)\n",
        "\n",
        "    outputs = {\"d loss\": [], \"c loss\": [], \"accuracy\": []}\n",
        "    loss, loss_c, epoch_accuracy = [], [], []\n",
        "\n",
        "    print(\"training...\")\n",
        "    #Learning\n",
        "    for epochnumber in range(epoch_num):\n",
        "        lc, ld, accuracy = [], [], [] # epoch loaders\n",
        "        for i in range(int(len(target_dataloader) / batchsize)):\n",
        "            #Load data for batch size \n",
        "            batch_is_ready = False\n",
        "            while not batch_is_ready:\n",
        "              try:\n",
        "                batch_target, _ = target_dataloader.next()\n",
        "                batch_is_ready = True\n",
        "              except: # some error in loading the data\n",
        "                if not target_dataloader.has_next():\n",
        "                    target_dataloader.on_epoch_end()\n",
        "                continue\n",
        "\n",
        "            batch_ref, batch_y = reference_dataloader.next()\n",
        "\n",
        "            #target data\n",
        "            #Get loss while learning\n",
        "            lc.append(model_t.train_on_batch(batch_target, np.zeros((batchsize, 4096))))\n",
        "\n",
        "            #reference data\n",
        "            #Get loss while learning\n",
        "            ref_output = model_r.train_on_batch(batch_ref, batch_y)\n",
        "            ld.append(ref_output[0])\n",
        "            accuracy.append(ref_output[1])\n",
        "            count = (epochnumber * int(len(target_dataloader) / batchsize)) + i\n",
        "\n",
        "            # if count % 50 == 0:\n",
        "            #   with batchs_writer.as_default():\n",
        "            #     tf.summary.scalar(\"d loss\", np.mean(ld), step=count)\n",
        "            #     tf.summary.scalar(\"c loss\", np.mean(lc), step=count)\n",
        "            #     tf.summary.scalar(\"accuracy\", np.mean(accuracy), step=count)\n",
        "            #   print(\"batch: {}: d loss {}, c loss {}, accuracy {}\".format(count, np.mean(ld), np.mean(lc), np.mean(accuracy)))\n",
        "\n",
        "        target_dataloader.on_epoch_end()\n",
        "        reference_dataloader.on_epoch_end()\n",
        "\n",
        "        outputs[\"d loss\"].append(np.mean(ld))\n",
        "        outputs[\"c loss\"].append(np.mean(lc))\n",
        "        outputs[\"accuracy\"].append(np.mean(accuracy))\n",
        "        with epochs_writer.as_default():\n",
        "          for key in outputs:\n",
        "            tf.summary.scalar(key, outputs[key][-1], step=epochnumber+1)\n",
        "        print(\"epoch: {}: d loss {}, c loss {}, accuracy {}\".format(epochnumber+1, outputs[\"d loss\"][-1], outputs[\"c loss\"][-1], outputs[\"accuracy\"][-1] ))\n",
        "\n",
        "        checkpoint_path = \"weights_after_{}_epochs\".format(epochnumber+1)\n",
        "        network.save_weights(os.path.join(ckpt_path, checkpoint_path))\n",
        "\n",
        "\n",
        "\n",
        "    #Result graph\n",
        "    plt.plot(outputs[\"d loss\"],label=\"Descriptive loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(outputs[\"c loss\"],label=\"Compact loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend()\n",
        "    plt.show() \n",
        "\n",
        "    plt.plot(outputs[\"accuracy\"],label=\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()   \n",
        "\n",
        "    return model_t\n",
        "\n",
        "\n",
        "\n",
        "model = train(train_s_loader, ref_loader, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model build...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 14s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 126,625,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 130,722,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "x_target is 3386 samples\n",
            "x_ref is 50000 samples\n",
            "training...\n",
            "epoch: 1: d loss 1.460319324165379, c loss 0.38151537905553357, accuracy 0.6582988777318369\n",
            "epoch: 2: d loss 1.491405485421256, c loss 0.23264440009893042, accuracy 0.651801535735381\n",
            "epoch: 3: d loss 1.4192389678965969, c loss 0.1943269023848879, accuracy 0.6535735380980507\n",
            "epoch: 4: d loss 1.4387270324997177, c loss 0.17160108383817568, accuracy 0.6618428824571766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d039a59553ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_s_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-d039a59553ac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(target_dataloader, reference_dataloader, epoch_num)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mbatch_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m#target data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-713a5e8d564a>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m           \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelevant_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-713a5e8d564a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m           \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelevant_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-713a5e8d564a>\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNRAOOuih_Mp"
      },
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def get_data_scores(model, tempates, data_batch):\n",
        "  templates_preds = model.predict(tempates)\n",
        "  test_preds = model.predict(data_batch)\n",
        "\n",
        "  templates_preds = templates_preds.reshape((len(tempates),-1))\n",
        "  test_preds = test_preds.reshape((len(data_batch),-1))\n",
        "\n",
        "  test_s_losses = np.zeros(len(test_preds))\n",
        "  for i in range(len(test_preds)):\n",
        "    losses = tf.keras.losses.mean_squared_error(templates_preds, tf.expand_dims(test_preds[i], axis=0))\n",
        "    test_s_losses[i] = np.array(tf.math.reduce_min(losses))\n",
        "\n",
        "  return test_s_losses\n",
        "\n",
        "\n",
        "def get_roc_curve(model, templates, negative_data, positive_data, output_path):\n",
        "  roc_path = os.path.join(output_path, \"roc_graphs\")\n",
        "\n",
        "  if not os.path.exists(roc_path):\n",
        "    os.makedirs(roc_path)\n",
        "  #Abnormal score\n",
        "  Z1 = get_data_scores(model, templates, negative_data)\n",
        "  Z2 = get_data_scores(model, templates, positive_data)\n",
        "\n",
        "    #Drawing of ROC curve\n",
        "  y_true = np.zeros(len(negative_data)+len(positive_data))\n",
        "  y_true[len(negative_data):] = 1 #0:Normal, 1：Abnormal\n",
        "\n",
        "  #Calculate FPR, TPR(, Threshould)\n",
        "  fpr, tpr, _ = metrics.roc_curve(y_true, np.hstack((Z1, Z2)))\n",
        "\n",
        "  #AUC\n",
        "  auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "  #Plot the ROC curve\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, label='DeepOneClassification(AUC = %.2f)'%auc)\n",
        "  plt.legend()\n",
        "  plt.title('ROC curve - after {} epochs'.format(EPOCH_NUM))\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.grid(True)\n",
        "  plt.savefig(os.path.join(roc_path, \"roc_graph.png\"))\n",
        "  plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5ZEzDL00OVX"
      },
      "source": [
        "### **Display roc curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMcZZ3Z7N3-r",
        "outputId": "a024ef09-44ea-43e1-afeb-4ec2e47c1095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "classes_num = 1000\n",
        "batch_size = 2\n",
        "size = 224\n",
        "preprocessing_func = vgg_preprocessing\n",
        "network_constractor = lambda : tf.keras.applications.VGG16(include_top=True, input_shape=(size, size, 3), weights='imagenet')\n",
        "\n",
        "\n",
        "\n",
        "output_path = \"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_20201004-110539\"\n",
        "ckpt_path = \"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_all_stab/ckpts\"\n",
        "roc_path = os.path.join(output_path, \"roc_graphs\")\n",
        "\n",
        "if not os.path.exists(roc_path):\n",
        "  os.makedirs(roc_path)\n",
        "\n",
        "EPOCH_NUM = 4\n",
        "model = network_constractor()\n",
        "model.load_weights(os.path.join(ckpt_path, \"weights_after_{}_epochs\".format(EPOCH_NUM))).expect_partial()\n",
        "model = Model(inputs=model.input,outputs=model.layers[-2].output)\n",
        "\n",
        "target_train_paths, target_train_labels = os.path.join(output_path, \"target_train_paths.txt\"), os.path.join(output_path, \"target_train_labels.txt\")\n",
        "target_test_paths, target_test_labels = os.path.join(output_path, \"target_test_paths.txt\"), os.path.join(output_path, \"target_test_labels.txt\")\n",
        "alien_test_paths, alien_test_labels = os.path.join(output_path, \"alien_test_paths.txt\"), os.path.join(output_path, \"alien_test_labels.txt\")\n",
        "\n",
        "train_s_loader = construct_with_files(target_train_paths, None, batch_size, (size,size), classes_num, False, preprocessing_func)\n",
        "test_s_loader = construct_with_files(target_test_paths, None, batch_size, (size,size), classes_num, False, preprocessing_func)\n",
        "test_b_loader = construct_with_files(alien_test_paths, None, batch_size, (size,size), classes_num, False, preprocessing_func)\n",
        "\n",
        "\n",
        "X_train_s, relevant_paths_train_s = train_s_loader.get_all_data(size=40)\n",
        "X_test_s, relevant_paths_test_s = test_s_loader.get_all_data(size=70)\n",
        "X_test_b, relevant_paths_test_b = test_b_loader.get_all_data(size=70)\n",
        "\n",
        "# train = model.predict(X_train_s)\n",
        "# test_s = model.predict(X_test_s)\n",
        "# test_b = model.predict(X_test_b)\n",
        "\n",
        "# train = train.reshape((len(X_train_s),-1))\n",
        "# test_s = test_s.reshape((len(X_test_s),-1))\n",
        "# test_b = test_b.reshape((len(X_test_b),-1))\n",
        "\n",
        "# test_s_losses = np.zeros(len(test_s))\n",
        "# for i in range(len(test_s)):\n",
        "#   losses = tf.keras.losses.mean_squared_error(train, tf.expand_dims(test_s[i], axis=0))\n",
        "#   test_s_losses[i] = np.array(tf.math.reduce_min(losses))\n",
        "\n",
        "# test_b_losses = np.zeros(len(test_b))\n",
        "# for i in range(len(test_b)):\n",
        "#   losses = tf.keras.losses.mean_squared_error(train, tf.expand_dims(test_b[i], axis=0))\n",
        "#   test_b_losses[i] = np.array(tf.math.reduce_min(losses))\n",
        "\n",
        "# #Abnormal score\n",
        "# Z1 = test_s_losses\n",
        "# Z2 = test_b_losses\n",
        "\n",
        "# def get_data_scores(model, tempates, data_batch):\n",
        "#   templates_preds = model.predict(tempates)\n",
        "#   test_preds = model.predict(data_batch)\n",
        "\n",
        "#   templates_preds = templates_preds.reshape((len(tempates),-1))\n",
        "#   test_preds = test_preds.reshape((len(data_batch),-1))\n",
        "\n",
        "#   test_s_losses = np.zeros(len(test_preds))\n",
        "#   for i in range(len(test_preds)):\n",
        "#     losses = tf.keras.losses.mean_squared_error(templates_preds, tf.expand_dims(test_preds[i], axis=0))\n",
        "#     test_s_losses[i] = np.array(tf.math.reduce_min(losses))\n",
        "\n",
        "#   return test_s_losses\n",
        "\n",
        "\n",
        "# def get_roc_curve(model, tempates, negative_data, positive_data, output_path):\n",
        "#   roc_path = os.path.join(output_path, \"roc_graphs\")\n",
        "\n",
        "#   if not os.path.exists(roc_path):\n",
        "#     os.makedirs(roc_path)\n",
        "#   #Abnormal score\n",
        "#   Z1 = get_data_scores(model, tempates, negative_data)\n",
        "#   Z2 = get_data_scores(model, tempates, positive_data)\n",
        "\n",
        "#     #Drawing of ROC curve\n",
        "#   y_true = np.zeros(len(negative_data)+len(positive_data))\n",
        "#   y_true[len(negative_data):] = 1 #0:Normal, 1：Abnormal\n",
        "\n",
        "#   #Calculate FPR, TPR(, Threshould)\n",
        "#   fpr, tpr, _ = metrics.roc_curve(y_true, np.hstack((Z1, Z2)))\n",
        "\n",
        "#   #AUC\n",
        "#   auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "#   #Plot the ROC curve\n",
        "#   plt.figure()\n",
        "#   plt.plot(fpr, tpr, label='DeepOneClassification(AUC = %.2f)'%auc)\n",
        "#   plt.legend()\n",
        "#   plt.title('ROC curve - after {} epochs'.format(EPOCH_NUM))\n",
        "#   plt.xlabel('False Positive Rate')\n",
        "#   plt.ylabel('True Positive Rate')\n",
        "#   plt.grid(True)\n",
        "#   plt.savefig(os.path.join(roc_path, \"epoch_{}.png\".format(EPOCH_NUM)))\n",
        "#   plt.show()\n",
        "\n",
        "\n",
        "get_roc_curve(model, X_train_s, X_test_s, X_test_b, output_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# #Convert to 0-1\n",
        "# ms = MinMaxScaler()\n",
        "# train = ms.fit_transform(train)\n",
        "# test_s = ms.transform(test_s)\n",
        "# test_b = ms.transform(test_b)\n",
        "\n",
        "# # fit the model\n",
        "# clf = LocalOutlierFactor(n_neighbors=5)\n",
        "# y_pred = clf.fit(train)\n",
        "\n",
        "# #Abnormal score\n",
        "# Z1 = -clf._decision_function(test_s)\n",
        "# Z2 = -clf._decision_function(test_b)\n",
        "\n",
        "# #Drawing of ROC curve\n",
        "# y_true = np.zeros(len(test_s)+len(test_b))\n",
        "# y_true[len(test_s):] = 1 #0:Normal, 1：Abnormal\n",
        "\n",
        "# #Calculate FPR, TPR(, Threshould)\n",
        "# fpr, tpr, _ = metrics.roc_curve(y_true, np.hstack((Z1, Z2)))\n",
        "\n",
        "# #AUC\n",
        "# auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# #Plot the ROC curve\n",
        "# plt.figure()\n",
        "# plt.plot(fpr, tpr, label='DeepOneClassification(AUC = %.2f)'%auc)\n",
        "# plt.legend()\n",
        "# plt.title('ROC curve - after {} epochs'.format(EPOCH_NUM))\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.grid(True)\n",
        "# plt.savefig(os.path.join(roc_path, \"epoch_{}.png\".format(EPOCH_NUM)))\n",
        "# plt.show()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV1bn/8c/DIPNgRSgVKEidwCJDcEJbUIuIOFULep1pxYlqL9YWr1bRn161aq1WHFBQUSA4XAWRFmslUhWRQVABEURmFIqChElInt8feyceDifJybCTnOzv+/U6L86en5WQ85y11t5rmbsjIiLxVauqAxARkaqlRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzSgQiETCzVmY2w8y2mtkDVR1PVTCzZ8zszqqOQ0qmRCCFzGyFme0ws1wz+zL8Q26ctM/xZvZW+AG3xcxeM7NOSfs0NbO/mtmq8Fyfh8stKrdEVWoI8B+gqbvfYGY5ZvabKC5kZj8ws41m9k4U55eaT4lAkp3h7o2BrkA34KaCDWZ2HPAGMAn4EdABWAC8a2YHh/vsB/wL6Az0A5oCxwGbgKOjCtrM6kR17jL6MbDIK+iJTTOrXczme4HFFXEdiSl310sv3B1gBXBKwvKfgdcTlv8NPJriuL8DY8P3vwG+AhqX4rqdgX8CX4fH/k+4/hngzoT9egNrkuL9I/ARsCt8/1LSuR8CHg7fNwNGA+uBtcCdQO0y/qz2B6YAG4FvwvdtEuLeDXwH5ALvAnnAznD5kXC/wxPKvQQYmHD+Z4DHgKnAtsTfS1IcxwMzgcuBd0qIeTBBwvgGmAb8OGGbA9cBywlqMvcBtcJttYBbgJXABmAs0Czh2BOA94DNwGrgsoQyjAReB7YCs4CO4TYDHgzP9y3wMXBkVf8NxPVV5QHoVX1eiYkAaBP+cT4ULjcMP8z6pDjucmB9+D4beLYU12wSfjDfANQPl48Jt6WTCOYDbYEGBN/CtwNNwu21w3MfGy6/AjwBNAJaAh8AV5bxZ3UAcG74c2kCvAi8mrA9OfYc4DcJy43CD83LgToEta//AJ0Sjt8C9Ao/iOuniKE2MA/oAVxGMYkAOAtYBhwRXu8W4L2E7Q5MB34AtAM+K4iXIIEsAw4GGgP/BzwXbvtx+CF/AVA3/Ll0TShDQU2wDjAOyA63nQrMBZoTJIUjgNZV/TcQ15eahiTZq2a2leBDagNwW7j+BwQfSOtTHLMeKGj/P6CIfYoyAPjS3R9w953uvtXdZ5Xi+IfdfbW773D3lQQfjOeE204Ctrv7+2bWCugP/M7dt7n7BoJvpOeX4lqF3H2Tu7/s7tvdfStwF/DzUpxiALDC3Z929z3u/iHwMvCrhH0mufu77p7v7jtTnOM6YJa7z03jelcBd7v7YnffA/wv0NXMfpywz73u/rW7rwL+SvDhDnAh8Bd3X+7uuQTNheeHzXH/Bbzp7hPcfXf4c5mfcM5X3P2D8JrjCJocIagxNSGoFVkYV2n+30gFUiKQZGe7exOCb9+H8/0H/DdAPtA6xTGtCb7NQvANMNU+RWkLfF6mSAOrk5bH8/0H2H+FyxB8c60LrDezzWa2maB20DLVScNO7oJXuxTbG5rZE2a20sy+BWYAzUtoy0/0Y+CYgljCeC4EflhM2RKv/yOCRHBzKa73UMK1vib4Jn5QEddbSdAPRPjvyqRtdYBWlPz7+zLh/XaCGgXu/hbwCEHT0QYzG2VmTdMsi1QwJQJJyd3fJqja3x8ubyNoi/5Vit0HEnQQA7wJnGpmjdK81GqCJodUthE0vRT4YYp9kjtjXwR6m1kbgppBQSJYTdCP0MLdm4evpu7eOdWF3b1xwmtVil1uAA4jaMZqCvwsXG9FlCU5ztXA2wmxNA+vdXUxxyQ6miDhLjKzLwn6Qo4O7/ZKlYxWEzSDJV6vgbu/l7BP24T37YB14ft1BIkkcdsegv6c1UDHYuIskrs/7O49gE7AocCNZTmPlJ8SgRTnr8AvzOyocHk4cKmZXWdmTcxs//A+8eOA28N9niP4cHjZzA43s1pmdoCZ/Y+Z9U9xjSlAazP7nZnVC897TLhtPtA/vD3yh8DvSgrY3TcStMc/DXzh7ovD9esJ7nh6ILy9tZaZdTSz0jTnJGoC7AA2m9kP+L4JrShfsXfCmwIcamYXm1nd8NXTzI5I8/p/B9oTNLV0BW4FPiRon89Lsf/jwE1m1hnAzJqZWXJSvzH8nbYFrgcmhusnAP9tZh3C24n/F5iY0NxzipkNNLM64e+6KyUIy3qMmdUlSPg7CWqcUgWUCKRI4YfqWIIPGdz9HYJOvl8S9AOsJOjkPMHdl4b77AJOAT4luCPmW4JO2RYEd40kX2Mr8AvgDIJmhKVAn3DzcwS3p64g+BCfmHx8EcaHMYxPWn8JsB+wiKCp6yVK14yV6K8EHdT/Ad4H/lHC/g8B55nZN2b2cFjuvgR9FOsIyn4vUC+di7v7Lnf/suBF0LG8O3yfav9XwvNnh01ZnwCnJe02iaADdz7BnT6jw/VjCH4XM4AvCD60fxuedxVB38sNBM1N84GjKFlT4EmC38NKgibF+9I4TiJg7pqYRiTuzMyBQ9x9WVXHIpVPNQIRkZhTIhARiTk1DYmIxJxqBCIiMVfdBuoqUYsWLbx9+/ZlOnbbtm00apTu7e01g8ocDypzPJSnzHPnzv2Pux+YalvGJYL27dszZ86cMh2bk5ND7969Kzagak5ljgeVOR7KU2YzW1nUNjUNiYjEnBKBiEjMKRGIiMRcxvURpLJ7927WrFnDzp2pRur9XrNmzVi8OF4TOanM8RBFmevXr0+bNm2oW7duhZ5Xqp8akQjWrFlDkyZNaN++PWZFDf4IW7dupUmTJpUYWdVTmeOhosvs7mzatIk1a9bQoUOHCjuvVE+RNQ2Z2Rgz22BmnxSx3czsYTNbZmYfmVn3sl5r586dHHDAAcUmARFJn5lxwAEHlFjLlpohyj6CZwgmLy/KacAh4WsIwfysZaYkIFKx9DcVH5E1Dbn7DDNrX8wuZxFMeO7A+2bW3Mxaa7o6EUk0ftYqJs1fu8/6zZt38NiSmVUQUdVpmr+LKB6dqMo+goPYe2q8NeG6fRKBmQ0hqDXQqlUrcnJy9trerFkztm7dWuIF8/Ly0tqvLJo3b07nzp3ZvXs3derU4YILLuDaa6+lVq2KrXR99913/OlPf+If//gHZsbhhx/OAw88wEEHHZRy/3TKPH78eB566CHMjDp16jBw4ECuu+46rrrqKvr168fZZ59d7rjXr1/PH/7wB5577jkALr/8cj799FMuvPBCNm/eTK9evejTp08JZ9nbypUrmTVrFgMHDgRg3rx5TJgwgXvuuadMv+cdO3bwy1/+kilTplC7djDJ18iRIxkxYgTLli2jWbNmAIwbN4558+bxwAMPFB7bv39/7rzzTrp3705ubi4333wz06dPp3nz5jRu3Jjbb7+dnj17ljqmAu7OH/7wB9544w0aNmzIY489Rteu38//kpeXx7p16+jX7/tK+Nq1axk0aBD33nsvjzzyCM8++yx16tShRYsWjBw5knbt2vGf//yHK664gldeeSXldXfu3LnP31tle3bWDlZtzaddk73/lvLy8ti8eXMVRVU1GjTIi+b3UdZZ79N5Ecyg9EkR26YQTGhSsPwvIKukc/bo0cOTLVq0aJ91qXz77bdp7VcWjRo1Knz/1Vdf+cknn+y33nprhV/nhhtu8MGDB/uePXvc3X3MmDHes2dPz8/PT7l/SWWeOnWqd+vWzdeuXevu7jt37vRRo0a5u/ull17qL774YgVGH1i/fr137Nix3OeZPn26n3766fusL+vv+ZFHHvG//vWve607+uij/YQTTvAxY8YUrnv66af92muv3Wu/n//85z579mx3dx80aJAPHz7c8/Ly3N19+fLlPmXKlDLFVOD111/3fv36eX5+vs+cOdOPPvrovbanKnP37t397bffdnf3t956y7dt2+bu7o8++qgPHDiwcL/LLrvM33nnnZTXTfdvK0oDH3/PBz7+3j7rp0+fXvnBVLHylBmY40V8rlZljWAte8+R2iZcl/FatmzJqFGj6NmzJyNGjCA/P5/hw4eTk5PDrl27uPbaa7nyyisBuO+++3jhhRfYtWsX55xzDrfffjsrVqygX79+9OjRg3nz5tG5c2fGjh0LwNNPP80XX3xR+I318ssvZ8yYMbz11lt07NiR0047jRNOOIH33nuPgw46iOeff54mTZrw+eefc+2117Jx40YaNmzIk08+yeGHH87dd9/N/fffz49+FMxTXq9ePa644op9ynTHHXfw2muvsWPHDo4//nieeOIJzIyHH36Yxx9/nDp16tCpUyeys7N5++23uf7664GgnXnGjBls2rSJAQMG8Mknn9C3b1/Wrl1L165d+dvf/sbo0aMZMGAA5513HrNnz+b6669n27Zt1KtXj3/9619s2rSJiy++mG3btgHwyCOPcPzxxzN8+HAWL15M165dufTSS+nWrRv3338/EyZM4Ouvv2bw4MEsX76chg0bMmrUKLp06cKIESNYtWoVy5cvZ9WqVfzud7/juuuuA4Jv+uPHfz+p2eeff05ubi6PPvood911F5dffnmJv/vPP/+cWbNmMW7cuMLaYIcOHcp9582kSZO45JJLMDOOPfZYNm/ezPr162ndOvUEa5999hkbNmzgxBNPBNirtnXsscfy/PPPFy6fffbZjBs3jl69epUrxlSKatYpjUXrv6VTa81rH6WqTASTgaFmlg0cA2zxCugfuP21hSxa923KbXl5eYUfoKXR6UdNue2MlHOcF+nggw8mLy+PDRs2MGnSJJo1a8bs2bPZtWsXvXr1om/fvixdupSlS5fywQcf4O6ceeaZzJgxg3bt2rFkyRJGjx5Nr169GDx4MI8++ih9+/alXbt2NG269x9FVlYWCxcupGPHjixdupQJEybw5JNPMnDgQCZNmsQVV1zBkCFDePzxxznkkEOYNWsW11xzDW+99RaffPIJPXr0KLE8Q4cO5dZbbwXg4osvZsqUKZxxxhncc889fPHFF9SrV6+wmn7//fczcuRIevXqRW5uLvXr19/rXJMnT2bAgAHMnz8fgNGjgxkRv/vuOwYNGsTEiRPp2bMn3377LQ0aNKBly5b885//pH79+ixdupQLLriAOXPmcM8993D//fczZcoUgL2qzLfddhvdunXj1Vdf5a233uKSSy4pvN6nn37K9OnT2bp1K4cddhhXX3017s7y5ctJHNAwOzub888/nxNPPJElS5bw1Vdf0apVq2J/TgsXLqRr165p/T8bNGgQS5Ys2Wf9sGHDuOSSS/Zat3btWtq2/f57U5s2bVi7dm2RiSA7O5tBgwal7PAdPXo0p532/SyVWVlZ3HLLLSXGWxaT5q8t9wd5p9ZNOatr6qZPqRiRJQIzmwD0BlqY2RqCyb3rArj748BUgrlOlwHbgZK/bmWoN954g48++oiXXnoJgC1btrB06VLeeOMN3njjDbp16wZAbm4uS5cupV27drRt27bwG9pFF13Eww8/TN++fUu8VocOHQrbjnv06MGqVavIzc3lvffe41e/+n6u8l27dpWqDNOnT+fPf/4z27dv5+uvv6Zz586cccYZdOnShQsvvJCzzz67sC+hV69eDBs2jAsvvJBf/vKXtGnTJq1rLFmyhNatWxe2pRckvG3btjF06FDmz59P7dq1+eyzz0o81zvvvMPLL78MwEknncSmTZv49tvgC8Lpp59OvXr1qFevHi1btuSrr76iVq1aNG/efK9zTJgwgVdeeYVatWpx7rnn8uKLLzJ06NAi76Yp7V02EyemOwVz6WVnZxf2xyR6/vnnmTNnDm+//XbhupYtW7Ju3brIYunUuikTrzwusvNL+UV519AFJWx34NqKvm5x39wr80Gj5cuXU7t2bVq2bIm787e//Y1TTz11r32mTZvGTTfdVNhMVGDFihX7fKiYGR07dmTVqlX7lGPu3LkMGDAACJp2CtSuXZs9e/aQn59P8+bNC78RJ+rcuTNz587lpJNOKrIsO3fu5JprrmHOnDm0bduWESNGFN5f/vrrrzNjxgxee+017rrrLj7++GOGDx/O6aefztSpU+nVqxfTpk3bp1ZQGg8++CCtWrViwYIF5Ofnl+tckPpn1KxZs73umf/4449ZunQpv/jFL4CgttKhQweGDh3KAQccwDfffLPXOb/++mtatGhB8+bNWbBgQVq1z9LUCA466CBWr/7+3oo1a9YUeYPAggUL2LNnzz41vTfffJO77rqLt99+e6+fwc6dO2nQoEGxsUrNprGGIrBx40auuuqqwm+Pp556Ko899hi7d+8Ggvbbbdu2ceqppzJmzBhyc3OBoPq/YcMGAFatWsXMmcGtcePHj+eEE06gUaNGXHrppQwbNoy8vDwAxo4dy/bt24v9IG/atCkdOnTgxRdfBIIbBBYsWADATTfdxI033siXX34JBB94Tz311F7HF3xAtmjRgtzc3MKaTX5+PqtXr6ZPnz7ce++9bNmyhdzcXD7//HN++tOf8sc//pGePXvy6aefpvVzO+yww1i/fj2zZ88GgsS9Z88etmzZQuvWralVqxbPPfdcYdmbNGlS5N1BJ554IuPGjQOCJqMWLVrs06SWaP/99ycvL6+wrBMmTGDEiBGsWLGCFStWsG7dOtatW8fKlSvp2bMn7777buHPbM6cOezatYu2bdvSsWNHsrKyuO222wpugmDFihW8/vrr+1xz4sSJzJ8/f59XchIAOPPMMxk7dizuzvvvv0+zZs2KbBaaMGECF1yw9/ewDz/8kCuvvJLJkyfTsmXLvbZ99tlnHHnkkUX+bKTmqxFDTFQHO3bsoGvXroW3j1588cUMGzYMgN/85jesWLGC7t274+4ceOCBvPrqq/Tt25fFixdz3HFBtblx48Y8//zz1K5dm8MOO4yRI0cyePBgOnXqxNVXXw3A3Xffze9//3sOPfRQatWqxeGHH84rr7xSYrPEuHHjuPrqq7nzzjvZvXs3559/PkcddRT9+/fnq6++4pRTTsHdMTMGDx6817HNmzfniiuu4Mgjj+SHP/xhYdNNXl4eF110EVu2bMHdue6662jevDl/+tOfmD59OrVq1aJz586cdtpprF9fcvfPfvvtx8SJE/ntb3/Ljh07aNCgAW+++SbXXHMN5557LmPHjqVfv36FE3N06dKF2rVrc9RRR3HZZZcVNrEBjBgxgsGDB9OlSxcaNmzIs88+W+L1+/btyzvvvMMpp5xCdnY2U6dO3Wv7OeecQ3Z2Nn/84x956KGH6N+/P/n5+TRu3JgJEyYUdg4/9dRT3HDDDfzkJz+hQYMGtGjRgvvuu6/E6xenf//+TJ06lZ/85Cc0bNiQp59+unBb165d+fe//124/MILL+wT+4033khubm5h82C7du2YPHkyEDT7nX766eWKTzJbxs1ZnJWV5ckT0yxevJgjjjiixGMzZQyaFStWFN5hU16ZUuaKVNYyz5s3jwcffDBl23p1V57f889+9jMmTZrE/vvvv8+2dP+2CiTfJVTQURxFH4EmpikdM5vr7lmptqlpSCTUvXt3+vTpU9j0FAcbN25k2LBhKZNAWRTcJVRAd/xkBjUNVUPt27evkNqAlF5ys1hNd+CBB1bIk+OJdJdQ5qkxiaCgfVtEKkZys3E6D4fp4a/MVCOahurXr8+mTZv2+Y8rImXj4XwEibfqJjf7pKKmoMxUI2oEbdq0Yc2aNWzcuLHY/Xbu3Fnue9AzjcocD1GUedMOZ/SHW9i+J7hNNsqOX6laNSIR1K1bN62xXHJycva6xTAOVOZ4iKLMg56YuVdTj77t11w1IhGISDRUA4gHJQKRGFLHrySqEZ3FIlI66viVRKoRiMSUmn2kgBKBSA2jZh8pLTUNidQwavaR0lKNQKQGUrOPlIYSgUiGSdX0s3nzDh5bEsxfoWYfKS01DYlkmJKaftTsI6WlGoFIBkpu+gnGqVdTkJSNagQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnN6oEykCqUzUmgyDSEhFU01ApEqlM5Iock0hIRUNNUIRKqYRgqVqqYagYhIzEWaCMysn5ktMbNlZjY8xfZ2ZjbdzD40s4/MrH+U8YiIyL4iSwRmVhsYCZwGdAIuMLNOSbvdArzg7t2A84FHo4pHRERSi7JGcDSwzN2Xu/t3QDZwVtI+DhTc/tAMWBdhPCIikoK5ezQnNjsP6OfuvwmXLwaOcfehCfu0Bt4A9gcaAae4+9wU5xoCDAFo1apVj+zs7DLFlJubS+PGjct0bKZSmau3u2ftAOCmYxqU6zyZVOaKojKXTp8+fea6e1aqbVV919AFwDPu/oCZHQc8Z2ZHunt+4k7uPgoYBZCVleW9e/cu08WCyTvKdmymUpmrt4LpJcs7qUwmlbmiqMwVJ8pEsBZom7DcJlyX6NdAPwB3n2lm9YEWwIYI4xKpFOk8LKaHw6Q6iLKPYDZwiJl1MLP9CDqDJyftswo4GcDMjgDqAxsjjEmk0qTzsJgeDpPqILIagbvvMbOhwDSgNjDG3Rea2R3AHHefDNwAPGlm/03QcXyZR9VpIVKBSvNtXw+LSXUXaR+Bu08FpiatuzXh/SKgV5QxiESh4Nt+cc06+rYvmaKqO4tFMpa+7UtNoSEmRERiTolARCTmlAhERGJOiUBEJOaUCEREYk6JQEQk5pQIRERiTolARCTmlAhERGIu7SeLzayhu2+PMhiR6ip5bCGNGio1SYk1AjM73swWAZ+Gy0eZmaaUlFhJHklU4whJTZJOjeBB4FTCIaTdfYGZ/SzSqESqIY0tJDVVWk1D7r7azBJX5UUTjkjVSzXEtJqCpCZLp7N4tZkdD7iZ1TWz3wOLI45LpMqkmlBGTUFSk6VTI7gKeAg4iGCqyTeAa6IMSqSqqRlI4iSdRHCYu1+YuMLMegHvRhOSiIhUpnSahv6W5joREclARdYIzOw44HjgQDMblrCpKcEcxCIZqaT5htUxLHFTXI1gP6AxQbJokvD6Fjgv+tBEopGqMziROoYlboqsEbj728DbZvaMu6+sxJhEIqfOYJHvpdNZvN3M7gM6A/ULVrr7SZFFJVJB9EyASMnS6SweRzC8RAfgdmAFMDvCmEQqjJ4JEClZOjWCA9x9tJldn9BcpEQgGUPNQCLFSycR7A7/XW9mpwPrgB9EF5JI+lI1/WzevIPHlswE1Awkko50EsGdZtYMuIHg+YGmwO8ijUokTQVNP0V92KsZSKRkJSYCd58Svt0C9IHCJ4tFqoXkpp+cnBx691ZTkEi6inugrDYwkGCMoX+4+ydmNgD4H6AB0K1yQpS4KunBL1DTj0hFKK5GMBpoC3wAPGxm64AsYLi7v1oZwUm8ldTsA2r6EakIxSWCLKCLu+ebWX3gS6Cju2+qnNBEdMePSGUo7jmC79w9H8DddwLLS5sEzKyfmS0xs2VmNryIfQaa2SIzW2hm40tzfhERKb/iagSHm9lH4XsDOobLBri7dynuxGEfw0jgF8AaYLaZTXb3RQn7HALcBPRy92/MrGU5yiIiImVQXCI4opznPhpY5u7LAcwsGzgLWJSwzxXASHf/BsDdN5TzmpIh1BEsUn2Yu0dzYrPzgH7u/ptw+WLgGHcfmrDPq8BnQC+Coa1HuPs/UpxrCDAEoFWrVj2ys7PLFFNubi6NGzcu07GZqrqW+e5ZO1i1NZ92TYof5eS4H9Whd9u6pTp3dS1zlFTmeChPmfv06TPX3bNSbUtr8voI1QEOAXoDbYAZZvZTd9+cuJO7jwJGAWRlZXnv3r3LdLHg/vKyHZupqmuZH1syk+bNiaQjuLqWOUoqczxEVeYoE8FagttPC7QJ1yVaA8xy993AF2b2GUFi0FhG1Vg6zTolUbOPSPWRzuijmFkDMzuslOeeDRxiZh3MbD/gfGBy0j6vEtQGMLMWwKHA8lJeRypZSRO7pEP3/4tUHyXWCMzsDOB+ghnLOphZV+AOdz+zuOPcfY+ZDQWmEbT/j3H3hWZ2BzDH3SeH2/qa2SIgD7hRzylkBt3fL1JzpNM0NILgDqAcAHefb2Yd0jm5u08FpiatuzXhvQPDwpdUU8lNQWrWEalZ0mka2u3uW5LWRXOrkVRLyU1BatYRqVnSqREsNLP/AmqHD4BdB7wXbVhS3agpSKTmSicR/Ba4GdgFjCdo178zyqCk6miOX5H4SScRHO7uNxMkA6nhUo34qaYgkZotnUTwgJn9EHgJmOjun0Qck1QxNQOJxEuJncXu3odgZrKNwBNm9rGZ3RJ5ZCIiUinSeqDM3b9094eBq4D5wK0lHCIiIhkinQfKjgAGAecCm4CJBBPZSzWTqqN38+YdPLZkZtrnUMewSPyk00cwhuDD/1R3XxdxPFIO6UztWBJ1DIvET4mJwN3Va5hBkjt6g9EK9SsUkaIVmQjM7AV3H2hmH7P3k8RpzVAmIiKZobgawfXhvwMqIxAREakaRd415O7rw7fXuPvKxBdwTeWEJyIiUUvn9tFfpFh3WkUHIiIiVaO4PoKrCb75H2xmHyVsagK8G3VgIiJSOYrrIxgP/B24GxiesH6ru38daVQiIlJpiksE7u4rzOza5A1m9gMlAxGRmqGkGsEAYC7B7aOWsM2BgyOMS0REKkmRicDdB4T/pjUtpYiIZKYS7xoys15m1ih8f5GZ/cXM2kUfmoiIVIZ0bh99DNhuZkcRDDb3OfBcpFGJiEilSScR7HF3B84CHnH3kQS3kIqISA2QzuijW83sJuBi4EQzqwXUjTYsSTWkdEk0hLSIlEU6NYJBBBPXD3b3L4E2wH2RRiWFQ0qXhoaQFpGySGcY6i/NbBzQ08wGAB+4+9joQxPNHSwilSGdu4YGAh8AvwIGArPM7LyoAxMRkcqRTh/BzUBPd98AYGYHAm8CL0UZmIiIVI50EkGtgiQQ2kSak95LelJ1DKvjV0QqSzqJ4B9mNg2YEC4PAqZGF1L8pJprWB2/IlJZ0uksvtHMfgmcEK4a5e6vRBtW/KhjWESqSnHzEfXK2aIAAA8pSURBVBwC3A90BD4Gfu/upbuxXVJKbgpSM5CIVKXi2vrHAFOAcwlGIP1baU9uZv3MbImZLTOz4cXsd66ZuZlllfYamSj5GQE1A4lIVSquaaiJuz8Zvl9iZvNKc2Izqw2MJJjqcg0w28wmu/uipP2aANcDs0pz/kynpiARqS6KSwT1zawb389D0CBx2d1LSgxHA8vcfTmAmWUTjFe0KGm//wfcC9xYythFRKQCFJcI1gN/SVj+MmHZgZNKOPdBwOqE5TXAMYk7mFl3oK27v25mRSYCMxsCDAFo1aoVOTk5JVw6tdzc3DIfW5E2b94BUCmxVJcyVyaVOR5U5opT3MQ0fSr8agnCwev+AlxW0r7uPgoYBZCVleW9e/cu0zVzcnIo67EV6bElMwHo3Tv6pqHqUubKpDLHg8pccaJ8MGwt0DZhuU24rkAT4Eggx8xWAMcCk+PSYSwiUl1EmQhmA4eYWQcz2w84H5hcsNHdt7h7C3dv7+7tgfeBM919ToQxiYhIknSeLC4Td99jZkOBaUBtYIy7LzSzO4A57j65+DNkpnTmEdBzAyJSnZSYCMzMgAuBg939jnC+4h+6+wclHevuU0kajsLdby1i395pRVzNpRouIpmeGxCR6iSdGsGjQD7BXUJ3AFuBl4GeEcaV0fSMgIhkknQSwTHu3t3MPgRw92/CNn9Bw0WISOZLp7N4d/iUsEPhfAT5kUaVQTRchIhkunRqBA8DrwAtzewu4DzglkijyjBqChKRTJbOMNTjzGwucDLB8BJnu/viyCMTEZFKkc5dQ+2A7cBrievcfVWUgYmISOVIp2nodYL+AQPqAx2AJUDnCOMSEZFKkk7T0E8Tl8OB4q6JLCIREalUpR5iIhx++pgSdxQRkYyQTh/BsITFWkB3YF1kEYmISKVKp4+gScL7PQR9Bi9HE46IiFS2YhNB+CBZE3f/fSXFIyIilazIPgIzq+PueUCvSoxHREQqWXE1gg8I+gPmm9lk4EVgW8FGd/+/iGOrljS2kIjUNOn0EdQHNhGMPlrwPIEDsUwEycNMa2whEcl0xSWCluEdQ5/wfQIo4JFGVc1pbCERqUmKSwS1gcbsnQAKxDoRiIjUJMUlgvXufkelRSIiIlWiuCeLU9UERESkhikuEZxcaVGIiEiVKTIRuPvXlRmIiIhUjVIPOiciIjWLEoGISMwpEYiIxJwSgYhIzCkRiIjEnBKBiEjMKRGIiMScEoGISMwpEYiIxFykicDM+pnZEjNbZmbDU2wfZmaLzOwjM/uXmf04ynhERGRfkSWCcL7jkcBpQCfgAjPrlLTbh0CWu3cBXgL+HFU8IiKSWpQ1gqOBZe6+3N2/A7KBsxJ3cPfp7r49XHwfaBNhPCIikkI6U1WW1UHA6oTlNcAxxez/a+DvqTaY2RBgCECrVq3IyckpU0C5ubllPrbA5s07AMp9nspSEWXONCpzPKjMFSfKRJA2M7sIyAJ+nmq7u48CRgFkZWV57969y3SdnJwcynpsgceWzASgd+/MmKqyIsqcaVTmeFCZK06UiWAt0DZhuU24bi9mdgpwM/Bzd98VYTwiIpJClH0Es4FDzKyDme0HnA9MTtzBzLoBTwBnuvuGCGMREZEiRJYI3H0PMBSYBiwGXnD3hWZ2h5mdGe52H9AYeNHM5pvZ5CJOJyIiEYm0j8DdpwJTk9bdmvD+lCivLyIiJdOTxSIiMadEICISc9Xi9tGqMn7WKibN3+dGpmItWv8tnVo3jSgiEZHKF+sawaT5a1m0/ttSHdOpdVPO6npQRBGJiFS+WNcIIPhgn3hlZjwcJiIShVjXCERERIlARCT2lAhERGJOiUBEJOaUCEREYk6JQEQk5pQIRERiTolARCTmlAhERGJOiUBEJOaUCEREYk6JQEQk5pQIRERiTolARCTmYjMM9fhZq3h21g4eWzKzcJ0mmRERiVGNYNL8tazamr/XOk0yIyISoxoBQLsmtTQJjYhIktjUCEREJDUlAhGRmFMiEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmFMiEBGJuUgTgZn1M7MlZrbMzIan2F7PzCaG22eZWfso4xERkX1FlgjMrDYwEjgN6ARcYGadknb7NfCNu/8EeBC4N6p4REQktShrBEcDy9x9ubt/B2QDZyXtcxbwbPj+JeBkM7MIYxIRkSRRDjp3ELA6YXkNcExR+7j7HjPbAhwA/CdxJzMbAgwBaNWqFTk5OaUOpmn+Lho0yCvTsZksNzdXZY4BlTkeoipzRow+6u6jgFEAWVlZ3rt371Kfo3dvyMnJoSzHZjKVOR5U5niIqsxRNg2tBdomLLcJ16Xcx8zqAM2ATRHGJCIiSaJMBLOBQ8ysg5ntB5wPTE7aZzJwafj+POAtd/cIYxIRkSSRNQ2Fbf5DgWlAbWCMuy80szuAOe4+GRgNPGdmy4CvCZKFiIhUokj7CNx9KjA1ad2tCe93Ar+KMgYRESmeniwWEYk5JQIRkZhTIhARiTklAhGRmLNMu1vTzDYCK8t4eAuSnlqOAZU5HlTmeChPmX/s7gem2pBxiaA8zGyOu2dVdRyVSWWOB5U5HqIqs5qGRERiTolARCTm4pYIRlV1AFVAZY4HlTkeIilzrPoIRERkX3GrEYiISBIlAhGRmKuRicDM+pnZEjNbZmbDU2yvZ2YTw+2zzKx95UdZsdIo8zAzW2RmH5nZv8zsx1URZ0UqqcwJ+51rZm5mGX+rYTplNrOB4e96oZmNr+wYK1oa/7fbmdl0M/sw/P/dvyrirChmNsbMNpjZJ0VsNzN7OPx5fGRm3ct9UXevUS+CIa8/Bw4G9gMWAJ2S9rkGeDx8fz4wsarjroQy9wEahu+vjkOZw/2aADOA94Gsqo67En7PhwAfAvuHyy2rOu5KKPMo4OrwfSdgRVXHXc4y/wzoDnxSxPb+wN8BA44FZpX3mjWxRnA0sMzdl7v7d0A2cFbSPmcBz4bvXwJONjOrxBgrWolldvfp7r49XHyfYMa4TJbO7xng/wH3AjsrM7iIpFPmK4CR7v4NgLtvqOQYK1o6ZXagafi+GbCuEuOrcO4+g2B+lqKcBYz1wPtAczNrXZ5r1sREcBCwOmF5Tbgu5T7uvgfYAhxQKdFFI50yJ/o1wTeKTFZimcMqc1t3f70yA4tQOr/nQ4FDzexdM3vfzPpVWnTRSKfMI4CLzGwNwfwnv62c0KpMaf/eS5QRk9dLxTGzi4As4OdVHUuUzKwW8BfgsioOpbLVIWge6k1Q65thZj91981VGlW0LgCecfcHzOw4glkPj3T3/KoOLFPUxBrBWqBtwnKbcF3KfcysDkF1clOlRBeNdMqMmZ0C3Ayc6e67Kim2qJRU5ibAkUCOma0gaEudnOEdxun8ntcAk919t7t/AXxGkBgyVTpl/jXwAoC7zwTqEwzOVlOl9fdeGjUxEcwGDjGzDma2H0Fn8OSkfSYDl4bvzwPe8rAXJkOVWGYz6wY8QZAEMr3dGEoos7tvcfcW7t7e3dsT9Iuc6e5zqibcCpHO/+1XCWoDmFkLgqai5ZUZZAVLp8yrgJMBzOwIgkSwsVKjrFyTgUvCu4eOBba4+/rynLDGNQ25+x4zGwpMI7jjYIy7LzSzO4A57j4ZGE1QfVxG0ClzftVFXH5plvk+oDHwYtgvvsrdz6yyoMspzTLXKGmWeRrQ18wWAXnAje6esbXdNMt8A/Ckmf03QcfxZZn8xc7MJhAk8xZhv8dtQF0Ad3+coB+kP7AM2A5cXu5rZvDPS0REKkBNbBoSEZFSUCIQEYk5JQIRkZhTIhARiTklAhGRmFMikGrJzPLMbH7Cq30x++ZWwPWeMbMvwmvNC59QLe05njKzTuH7/0na9l55YwzPU/Bz+cTMXjOz5iXs3zXTR+OU6On2UamWzCzX3RtX9L7FnOMZYIq7v2RmfYH73b1LOc5X7phKOq+ZPQt85u53FbP/ZQSjrg6t6Fik5lCNQDKCmTUO51GYZ2Yfm9k+I42aWWszm5HwjfnEcH1fM5sZHvuimZX0AT0D+El47LDwXJ+Y2e/CdY3M7HUzWxCuHxSuzzGzLDO7B2gQxjEu3JYb/pttZqcnxPyMmZ1nZrXN7D4zmx2OMX9lGj+WmYSDjZnZ0WEZPzSz98zssPBJ3DuAQWEsg8LYx5jZB+G+qUZslbip6rG39dIr1Yvgqdj54esVgqfgm4bbWhA8VVlQo80N/70BuDl8X5tgvKEWBB/sjcL1fwRuTXG9Z4Dzwve/AmYBPYCPgUYET2UvBLoB5wJPJhzbLPw3h3DOg4KYEvYpiPEc4Nnw/X4Eo0g2AIYAt4Tr6wFzgA4p4sxNKN+LQL9wuSlQJ3x/CvBy+P4y4JGE4/8XuCh835xgLKJGVf371qtqXzVuiAmpMXa4e9eCBTOrC/yvmf0MyCf4JtwK+DLhmNnAmHDfV919vpn9nGCyknfDoTX2I/gmncp9ZnYLwTg1vyYYv+YVd98WxvB/wInAP4AHzOxeguakf5eiXH8HHjKzekA/YIa77wibo7qY2Xnhfs0IBov7Iun4BmY2Pyz/YuCfCfs/a2aHEAyzULeI6/cFzjSz34fL9YF24bkkppQIJFNcCBwI9HD33RaMKFo/cQd3nxEmitOBZ8zsL8A3wD/d/YI0rnGju79UsGBmJ6fayd0/s2Cug/7AnWb2L3e/I51CuPtOM8sBTgUGEUy0AsFsU79192klnGKHu3c1s4YE4+9cCzxMMAHPdHc/J+xYzynieAPOdfcl6cQr8aA+AskUzYANYRLoA+wz57IF8zB/5e5PAk8RTPf3PtDLzAra/BuZ2aFpXvPfwNlm1tDMGhE06/zbzH4EbHf35wkG80s1Z+zusGaSykSCgcIKahcQfKhfXXCMmR0aXjMlD2abuw64wb4fSr1gKOLLEnbdStBEVmAa8FsLq0cWjEorMadEIJliHJBlZh8DlwCfptinN7DAzD4k+Lb9kLtvJPhgnGBmHxE0Cx2ezgXdfR5B38EHBH0GT7n7h8BPgQ/CJprbgDtTHD4K+KigszjJGwQTA73pwfSLECSuRcA8CyYtf4ISauxhLB8RTMzyZ+DusOyJx00HOhV0FhPUHOqGsS0MlyXmdPuoiEjMqUYgIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJz/x/548G9o114wAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsJKYjWqjlEA",
        "outputId": "1dba6bfd-6d6b-4eb2-da38-394a8a048d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\"))\n",
        "# os.rename(\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_all_stab (1)\", \"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_all_stab\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['experiment_knives_only', 'experiment_all_stab']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAV_qNzn0b5_"
      },
      "source": [
        "### **Writing predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4jO1LYCDNXf"
      },
      "source": [
        "results_path = os.path.join(output_path, \"preds\")\n",
        "\n",
        "PRED_S_RESULTS_PATH = os.path.join(output_path, \"pred_s_results.txt\")\n",
        "PRED_B_RESULTS_PATH = os.path.join(output_path, \"pred_b_results.txt\")\n",
        "\n",
        "\n",
        "with open(PRED_S_RESULTS_PATH, \"w\") as rf:\n",
        "  test_s_scores = list(zip(relevant_paths_test_s, Z1))\n",
        "  for item in test_s_scores:\n",
        "    rf.write(\"{}\\n\".format(item))\n",
        "\n",
        "with open(PRED_B_RESULTS_PATH, \"w\") as rf:\n",
        "  test_b_scores = list(zip(relevant_paths_test_b, Z2))\n",
        "  for item in test_b_scores:\n",
        "    rf.write(\"{}\\n\".format(item))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpIuD54500b2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FLNGMf_ECQH"
      },
      "source": [
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "import numpy as np\n",
        "import math\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "\n",
        "\n",
        "def map_path_to_class(paths):\n",
        "  paths2cls = dict()\n",
        "  for path in paths:\n",
        "    cls = path.split('/')[-2]\n",
        "    paths2cls[path] = cls\n",
        "  return paths2cls\n",
        "\n",
        "\n",
        "def getImage(path, zoom):\n",
        "  image = plt.imread(path)\n",
        "  image = resize(image, (224, 224))\n",
        "  return OffsetImage(image, zoom=zoom)\n",
        "\n",
        "\n",
        "def create_images_graph(output_path, paths, scores, name, zoom, columns, max_objects=None):\n",
        "  scores_graph_path = os.path.join(output_path, \"score_graphs\")\n",
        "  if not ps.path.exists(scores_graph_path):\n",
        "    os.makedirs(scores_graph_path)\n",
        "  if max_objects is None:\n",
        "    max_objects = len(scores)\n",
        "  paths2cls = map_path_to_class(paths)\n",
        "  indices =  np.argsort(scores)[:max_objects]\n",
        "  scores = scores[indices]\n",
        "\n",
        "  step = 10\n",
        "\n",
        "  x = list(range(columns)) * math.ceil(len(indices)/float(columns))\n",
        "\n",
        "  x = [step * i for i in x]\n",
        "  x = x[:len(scores)]\n",
        "  fig, ax = plt.subplots()\n",
        "  # ax.scatter(x, scores[indices]) \n",
        "  for i in range(max_objects):\n",
        "    idx = indices[i]\n",
        "    ab = AnnotationBbox(getImage(paths[idx], zoom), (x[i], scores[i]), frameon=False)\n",
        "    ax.scatter(x[i], scores[i]) \n",
        "    ax.add_artist(ab)\n",
        "  ax.update_datalim(np.column_stack([x, scores]))\n",
        "  ax.autoscale(-1*max(scores),max(scores)*1.1)\n",
        "  ax.set_xlim(-1,max(x)*1.1)\n",
        "  plt.ylabel(\"classifier score\")\n",
        "  plt.xlabel(\"axis without meaning\")\n",
        "  plt.title(name)\n",
        "  plt.savefig(os.path.join(output_path, \"scores visualization_of_{}.png\".format(name)), dpi=500)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# results_output_path = os.path.join(scores_graph_path, \"results_for_epoch_{}\".format(EPOCH_NUM))\n",
        "# if not os.path.exists(results_output_path):\n",
        "#   os.makedirs(results_output_path)\n",
        "\n",
        "# norm_factor=max(np.max(Z1), np.max(Z2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# create_images_graph(results_output_path, relevant_paths_test_s[:40], Z1[:40], \"scores_for_knives_images_epoch_{}\".format(EPOCH_NUM), 0.08, 20)\n",
        "# create_images_graph(results_output_path, relevant_paths_test_s, Z1, \"the_smallest_scores_for_knives_images_epoch_{}\".format(EPOCH_NUM), 0.08, 20, 20)\n",
        "# create_images_graph(results_output_path, relevant_paths_test_b[:40], Z2[:40], \"scores_for_alien_images_epoch_{}\".format(EPOCH_NUM), 0.08, 20)\n",
        "# create_images_graph(results_output_path, relevant_paths_test_b, Z2, \"the_smallest_scores_for_alien_images_epoch_{}\".format(EPOCH_NUM), 0.05, 20, 20)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-bj0yDpkLga",
        "outputId": "495407fb-ba98-440d-fcd5-efe4c3c8ad19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "new_network = network_constractor()\n",
        "\n",
        "new_network = Model(inputs=new_network.input,outputs=new_network.layers[-2].output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# new_mobile = tf.keras.applications.MobileNetV2(include_top=True, input_shape=(size, size, 3), alpha=alpha, weights='imagenet')\n",
        "\n",
        "untrained_test_s = new_network.predict(X_test_s)\n",
        "untrained_test_b = new_network.predict(X_test_b)\n",
        "\n",
        "untrained_test_s_embedded = TSNE(n_components=2).fit_transform(untrained_test_s)\n",
        "untrained_test_b_embedded = TSNE(n_components=2).fit_transform(untrained_test_b)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(untrained_test_s_embedded[:, 0],untrained_test_s_embedded[:,1], label=\"Target\")\n",
        "plt.scatter(untrained_test_b_embedded[:, 0],untrained_test_b_embedded[:,1], label=\"Alien\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.title(\"features before training (TSNE)\")\n",
        "plt.savefig(os.path.join(output_path, \"features_before_training.png\"))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "test_s_embedded = TSNE(n_components=2).fit_transform(test_s)\n",
        "test_b_embedded = TSNE(n_components=2).fit_transform(test_b)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(test_s_embedded[:, 0],test_s_embedded[:,1], label=\"Target\")\n",
        "plt.scatter(test_b_embedded[:, 0],test_b_embedded[:,1], label=\"Alien\")\n",
        "plt.title(\"features after {} epochs (TSNE)\".format(EPOCH_NUM))\n",
        "plt.savefig(os.path.join(output_path, \"features_after_{}_epochs.png\".format(EPOCH_NUM)))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMYIE7v5lj9h"
      },
      "source": [
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model, templates):\n",
        "        # store the model, the class index used to measure the class\n",
        "        # activation map, and the layer to be used when visualizing\n",
        "        # the class activation map\n",
        "        self.model = Model(inputs=model.input, outputs=model.layers[-1].output)\n",
        "        self.templates = templates\n",
        "        self.layerName = self.find_target_layer()\n",
        "\n",
        "    def find_target_layer(self):\n",
        "        # attempt to find the final convolutional layer in the network\n",
        "        # by looping over the layers of the network in reverse order\n",
        "        for layer in reversed(self.model.layers):\n",
        "            # check to see if the layer has a 4D output\n",
        "            if len(layer.output_shape) == 4:\n",
        "                return layer.name\n",
        "        # otherwise, we could not find a 4D layer so the GradCAM\n",
        "        # algorithm cannot be applied\n",
        "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
        "\n",
        "\n",
        "    def compute_heatmap(self, image,eps=1e-8):\n",
        "        # construct our gradient model by supplying (1) the inputs\n",
        "        # to our pre-trained model, (2) the output of the (presumably)\n",
        "        # final 4D layer in the network, and (3) the output of the\n",
        "        # softmax activations from the model\n",
        "        gradModel = Model(\n",
        "            inputs=[self.model.inputs],\n",
        "            outputs=[self.model.get_layer(self.layerName).output,\n",
        "                     self.model.output])\n",
        "        # record operations for automatic differentiation\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # cast the image tensor to a float-32 data type, pass the\n",
        "            # image through the gradient model, and grab the loss\n",
        "            # associated with the specific class index\n",
        "            inputs = tf.cast(image, tf.float32)\n",
        "            inputs = tf.Variable(inputs)\n",
        "            tape.watch(inputs)\n",
        "\n",
        "            (convOutputs, predictions) = gradModel(inputs)\n",
        "            (t_convOutputs, t_predictions) = gradModel(self.templates)\n",
        "            train = tf.reshape(t_predictions, (len(self.templates), -1))\n",
        "            test = tf.reshape(predictions, (len(image), -1))\n",
        "            losses = tf.keras.losses.mean_squared_error(train, test)\n",
        "\n",
        "            loss = tf.math.reduce_min(losses)\n",
        "\n",
        "        # use automatic differentiation to compute the gradients\n",
        "        grads = tape.gradient(loss, convOutputs)\n",
        "        # compute the guided gradients\n",
        "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
        "        castGrads = tf.cast(grads > 0, \"float32\")\n",
        "        guidedGrads = castConvOutputs * castGrads * grads\n",
        "        # the convolution and guided gradients have a batch dimension\n",
        "        # (which we don't need) so let's grab the volume itself and\n",
        "        # discard the batch\n",
        "        convOutputs = convOutputs[0]\n",
        "        guidedGrads = guidedGrads[0]\n",
        "\n",
        "        # compute the average of the gradient values, and using them\n",
        "        # as weights, compute the ponderation of the filters with\n",
        "        # respect to the weights\n",
        "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
        "        # grab the spatial dimensions of the input image and resize\n",
        "        # the output class activation map to match the input image\n",
        "        # dimensions\n",
        "        (w, h) = (image.shape[2], image.shape[1])\n",
        "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "        # normalize the heatmap such that all values lie in the range\n",
        "        # [0, 1], scale the resulting values to the range [0, 255],\n",
        "        # and then convert to an unsigned 8-bit integer\n",
        "        numer = heatmap - np.min(heatmap)\n",
        "        denom = (heatmap.max() - heatmap.min()) + eps\n",
        "        heatmap = numer / denom\n",
        "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
        "        # return the resulting heatmap to the calling function\n",
        "        return heatmap, loss\n",
        "\n",
        "    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
        "                        colormap=cv2.COLORMAP_JET ):\n",
        "        # apply the supplied color map to the heatmap and then\n",
        "        # overlay the heatmap on the input image\n",
        "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
        "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
        "        # return a 2-tuple of the color mapped heatmap and the output,\n",
        "        # overlaid image\n",
        "        return (heatmap, output)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grJNkybfin_",
        "outputId": "1c8ee2ba-2c2e-4db6-cb4f-da694c418396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import imutils\n",
        "import re\n",
        "\n",
        "\n",
        "def image_name(image_path):\n",
        "  try:\n",
        "    regex = \".*[\\\\/|\\\\\\](.*)[\\\\/|\\\\\\](.*).(jpg|JPEG)\"\n",
        "    m = re.match(regex, image_path)\n",
        "    return m.group(1) + \"_\" + m.group(2)\n",
        "  except:\n",
        "    print(image_path)\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_gradCam_image(models_dict, image_path, output_path, templates):\n",
        "\n",
        "    image = read_image(image_path, (size, size))\n",
        "    orig = np.array(Image.open(image_path).convert('RGB'))\n",
        "\n",
        "    all_outputs = []\n",
        "    labels_str = \"\"\n",
        "\n",
        "    for model_name in models_dict:\n",
        "      model = models_dict[model_name]\n",
        "      cam = GradCAM(model, templates)\n",
        "\n",
        "      heatmap, loss = cam.compute_heatmap(np.copy(image))\n",
        "      heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
        "      (heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n",
        "      all_outputs.append(np.hstack([orig, heatmap, output]))\n",
        "      labels_str += \"model {}: loss {}\\n\".format(model_name, loss)\n",
        "    output = np.vstack(all_outputs)\n",
        "    output = imutils.resize(output, height=2100)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(output)\n",
        "    plt.title(labels_str)\n",
        "    plt.savefig(os.path.join(output_path, image_name(image_path)), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "    print(image_path)\n",
        "\n",
        "def read_image(image_path, input_size):\n",
        "    image = load_img(image_path, target_size=input_size)\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = imagenet_utils.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def get_results_for_imagesdir(models_dict, input_path, output_path, templates):\n",
        "    dirs = os.listdir(input_path)\n",
        "    for dir_name in dirs:\n",
        "        dir_path = os.path.join(input_path, dir_name)\n",
        "        output_dir_path = os.path.join(output_path, dir_name)\n",
        "        if not os.path.exists(output_dir_path):\n",
        "            os.makedirs(output_dir_path)\n",
        "        images = os.listdir(dir_path)\n",
        "        for image_name in images:\n",
        "            full_path = os.path.join(dir_path, image_name)\n",
        "            get_gradCam_image(models_dict, full_path, output_dir_path, templates)\n",
        "\n",
        "cam_visulalization_path = \"/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization\"\n",
        "cam_output = os.path.join(output_path, \"cam_output\")\n",
        "if not os.path.exists(cam_output):\n",
        "  os.makedirs(cam_output)\n",
        "\n",
        "templates = X_train_s\n",
        "\n",
        "imagenet_network = network_constractor()\n",
        "\n",
        "knives_only_ckpts_path = \"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_knives_only/ckpts\"\n",
        "\n",
        "knives_only_model = network_constractor()\n",
        "knives_only_model.load_weights(os.path.join(knives_only_ckpts_path, \"weights_after_{}_epochs\".format(5))).expect_partial()\n",
        "knives_only_model = Model(inputs=knives_only_model.input,outputs=knives_only_model.layers[-2].output)\n",
        "\n",
        "\n",
        "get_results_for_imagesdir({\"doc model - all stab\":model, \"doc model - knives only\":knives_only_model, \"imagenet model\":imagenet_network}, cam_visulalization_path, cam_output, X_train_s)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/nunchaku.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/EIFFEL-TOWER.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/flag.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/flowers pot.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/pot.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/violin_bow.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/bow_tie.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/chair.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/swimsuit.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/kite.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/basketball.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/saw.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/shoe.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/heals.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/hat.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/lamp.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/broom.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/fishing_rod.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/toothbrush.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/spoon.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/fork.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/bag.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/ladder.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/hook.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/earing_hook.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/coin.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/crown.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/bottle.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/triangle.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/pan.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/wire.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/cup.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/socks.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/paper hat.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/wine opener.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/finger.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/plastic_road_cone.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/icecream_cone.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/plate.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/heart plate.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/watch.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/baloon.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/candle.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/unicorn_baloon.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/unicorn.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/disney_castle.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/lipstick.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/eyeliner.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/sharp_heals.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/pizza-triangle.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/party_flags.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/wine_glass.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/vase.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/party_hat.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/false/box.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/neadle.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/syringe.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/bow_and_arrow.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/arrow.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/toothpick.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/nail.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/hook.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/swordfish.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/screwdrivers.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/drill.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/broken glass.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/close_scissors.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/open_scissors.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/can_opener.jpg\n",
            "/content/drive/My Drive/Colab Notebooks/affordances/datasets/clean_alien_visulization/0true/pencil.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A63sKm9i_dgX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px9U2lrZJf1U"
      },
      "source": [
        "Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lfunWuFJjIs",
        "outputId": "92791830-5898-4ca3-a6a9-c14348507717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# NAME= \"experiment_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "NAME = \"experiment_test\"\n",
        "OUTPUT_PATH =  os.path.join(\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\", NAME)\n",
        "\n",
        "if not os.path.exists(OUTPUT_PATH):\n",
        "  os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "size = 224\n",
        "classes_num = 1000\n",
        "preprocessing_func = vgg_preprocessing\n",
        "network_constractor = lambda : tf.keras.applications.VGG16(include_top=True, input_shape=(size, size, 3), weights='imagenet')\n",
        "\n",
        "\n",
        "# creates_relevant_models\n",
        "EPOCH_NUM = 4\n",
        "models = dict()\n",
        "\n",
        "## model with all the stabbing data\n",
        "all_stab_model = network_constractor()\n",
        "all_stab_ckpt_path = os.path.join(\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_all_stab\", \"ckpts\")\n",
        "all_stab_model.load_weights(os.path.join(all_stab_ckpt_path, \"weights_after_{}_epochs\".format(EPOCH_NUM))).expect_partial()\n",
        "all_stab_model = Model(inputs=all_stab_model.input,outputs=all_stab_model.layers[-2].output)\n",
        "models[\"all_stab_model\"]= all_stab_model\n",
        "\n",
        "## model with only knives data\n",
        "knives_only_model = network_constractor()\n",
        "knives_only_ckpt_path = os.path.join(\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_knives_only\", \"ckpts\")\n",
        "knives_only_model.load_weights(os.path.join(knives_only_ckpt_path, \"weights_after_{}_epochs\".format(EPOCH_NUM))).expect_partial()\n",
        "knives_only_model = Model(inputs=knives_only_model.input,outputs=knives_only_model.layers[-2].output)\n",
        "models[\"knives_only_model\"]= knives_only_model\n",
        "\n",
        "## model with imagenet weights\n",
        "untrainbed_model = network_constractor()\n",
        "untrainbed_model = Model(inputs=untrainbed_model.input,outputs=untrainbed_model.layers[-2].output)\n",
        "models[\"untrainbed_model\"]= untrainbed_model\n",
        "\n",
        "\n",
        "# Data loaders\n",
        "target_train_paths, target_train_labels = os.path.join(OUTPUT_PATH, \"target_train_paths.txt\"), os.path.join(OUTPUT_PATH, \"target_train_labels.txt\")\n",
        "target_test_paths, target_test_labels = os.path.join(OUTPUT_PATH, \"target_test_paths.txt\"), os.path.join(OUTPUT_PATH, \"target_test_labels.txt\")\n",
        "alien_test_paths, alien_test_labels = os.path.join(OUTPUT_PATH, \"alien_test_paths.txt\"), os.path.join(OUTPUT_PATH, \"alien_test_labels.txt\")\n",
        "\n",
        "train_s_loader = construct_with_files(target_train_paths, None, 2, (size,size), classes_num, False, preprocessing_func)\n",
        "test_s_loader = construct_with_files(target_test_paths, None, 2, (size,size), classes_num, False, preprocessing_func)\n",
        "test_b_loader = construct_with_files(alien_test_paths, None, 2, (size,size), classes_num, False, preprocessing_func)\n",
        "\n",
        "templates, templates_paths = train_s_loader.get_all_data(size=40)\n",
        "target_test, target_test_paths = test_s_loader.get_all_data(size=70)\n",
        "alien_test, alien_test_paths = test_b_loader.get_all_data(size=70)\n",
        "\n",
        "\n",
        "# Creates epoch dirs\n",
        "get_epoch_dir = lambda model_name, epoch: os.path.join(os.path.join(OUTPUT_PATH, model_name), \"epoch_{}\".format(epoch))\n",
        "for model_name in models:\n",
        "  model_dir = os.path.join(OUTPUT_PATH, model_name)\n",
        "  if not os.path.exists(get_epoch_dir(model_dir, EPOCH_NUM)):\n",
        "    os.makedirs(get_epoch_dir(model_dir, EPOCH_NUM))\n",
        "\n",
        "\n",
        "# Creates roc curve graph\n",
        "for model_name in models:\n",
        "  get_roc_curve(models[model_name], templates, target_test, alien_test, get_epoch_dir(model_name, EPOCH_NUM))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Creates scores graphs\n",
        "for model_name in models:\n",
        "  Z1 = get_data_scores(models[model_name], templates, target_test)\n",
        "  Z2 = get_data_scores(models[model_name], templates, alien_test)\n",
        "  scores_graph_output_path = get_epoch_dir(model_name, EPOCH_NUM)\n",
        "  create_images_graph(scores_graph_output_path, target_test_labels[:40], Z1[:40], \"scores_for_knives_images\", 0.08, 20)  # displays the first 40's examples\n",
        "  create_images_graph(scores_graph_output_path, target_test_labels, Z1, \"the_smallest_scores_for_knives_images\", 0.08, 20, 20) # the 20's examples with the lowest score\n",
        "  create_images_graph(scores_graph_output_path, alien_test_paths[:40], Z2[:40], \"scores_for_alien_images\", 0.08, 20) # displays the first 40's examples\n",
        "  create_images_graph(scores_graph_output_path, alien_test_paths, Z2, \"the_smallest_scores_for_alien_images\", 0.05, 20, 20) # the 20's examples with the lowest score\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e4aa8945d2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mall_stab_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_constractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mall_stab_ckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_all_stab\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ckpts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mall_stab_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_stab_ckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weights_after_{}_epochs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mall_stab_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_stab_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_stab_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all_stab_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mall_stab_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m         \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     93\u001b[0m   \"\"\"\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_all_stab/ckpts/weights_after_4_epochs: Not found: /content/drive/My Drive/Colab Notebooks/affordances/experiments/experiment_all_stab/ckpts; No such file or directory"
          ]
        }
      ]
    }
  ]
}